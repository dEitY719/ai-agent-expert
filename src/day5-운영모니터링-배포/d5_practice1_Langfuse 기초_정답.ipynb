{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_intro_md"
   },
   "source": [
    "# Langfuse ê¸°ì´ˆ\n",
    "\n",
    "### ì‹¤ìŠµ ëª©í‘œ\n",
    "5ì¼ì°¨ì˜ ì²« ì‹¤ìŠµì—ì„œëŠ”, ë³µì¡í•œ Agent ì‹œìŠ¤í…œì˜ ë‚´ë¶€ë¥¼ íˆ¬ëª…í•˜ê²Œ ë“¤ì—¬ë‹¤ë³´ëŠ” ê´€ì¸¡ ê°€ëŠ¥ì„±(Observability)ì„ ìœ„í•˜ì—¬ `Langfuse`ë¥¼ í™œìš©í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ì‹œìŠ¤í…œì„ ë¶„ì„í•˜ê³ , í‰ê°€í•˜ë©°, ê°œì„ í•˜ëŠ” ë‹¤ì–‘í•œ ê¸°ëŠ¥ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆ Part 1ì—ì„œëŠ” `Langfuse`ì˜ ê¸°ë³¸ì ì¸ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•˜ê³ , ê°„ë‹¨í•œ í•¨ìˆ˜ì™€ LLM í˜¸ì¶œì„ ì¶”ì í•˜ëŠ” ê³¼ì •ì„ ì‚´í´ë´…ë‹ˆë‹¤.\n",
    "\n",
    "1. Trace, Span, Observation, Generation ë“± `Langfuse` ëŒ€ì‹œë³´ë“œë¥¼ êµ¬ì„±í•˜ëŠ” í•µì‹¬ ë°ì´í„° ëª¨ë¸ì˜ ì˜ë¯¸ì™€ ê´€ê³„ë¥¼ ì´í•´í•©ë‹ˆë‹¤.\n",
    "2. `Langfuse`ì˜ ê°€ì¥ ê°„ë‹¨í•œ ì¶”ì  ê¸°ëŠ¥ì¸ `@trace()` ë°ì½”ë ˆì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬, ì¼ë°˜ Python í•¨ìˆ˜ì˜ ì‹¤í–‰(ì…ë ¥, ì¶œë ¥, ì†Œìš” ì‹œê°„, ì—ëŸ¬)ì„ ìë™ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "3. `LangChain`ìœ¼ë¡œ êµ¬ì„±ëœ LLM ì²´ì¸ì˜ ì‹¤í–‰ ê³¼ì •ì„ ì¶”ì í•˜ê¸° ìœ„í•´ `Langfuse`ì˜ `CallbackHandler`ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ìµíˆê³ , LLM í˜¸ì¶œê³¼ ê´€ë ¨ëœ ì •ë³´(í† í° ì‚¬ìš©ëŸ‰, ë¹„ìš©, ì§€ì—° ì‹œê°„ ë“±)ê°€ ì–´ë–»ê²Œ ìë™ìœ¼ë¡œ ê¸°ë¡ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_install_code"
   },
   "outputs": [],
   "source": [
    "# !pip install langfuse langchain-google-genai pydantic instructor jsonref -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_api_keys_code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Google API í‚¤ ì„¤ì •\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"\n",
    "\n",
    "# 2. Langfuse API í‚¤ ì„¤ì •\n",
    "# https://cloud.langfuse.com/ ì—ì„œ ìƒì„±í•œ í”„ë¡œì íŠ¸ì˜ API í‚¤\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"YOUR_API_KEY\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"YOUR_API_KEY\"\n",
    "# Hostì˜ ê²½ìš° í´ë¼ìš°ë“œì˜ êµ­ê°€ë¥¼ í™•ì¸í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_decorator_md"
   },
   "source": [
    "### 1. `@observe()` ë°ì½”ë ˆì´í„°ë¡œ ì¼ë°˜ í•¨ìˆ˜ ì¶”ì í•˜ê¸°\n",
    "\n",
    "`Langfuse`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•ì€ `@observe()` ë°ì½”ë ˆì´í„°ë¥¼ ì¶”ì í•˜ê³  ì‹¶ì€ í•¨ìˆ˜ ìœ„ì— ë¶™ì´ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ë°ì½”ë ˆì´í„°ëŠ” í•´ë‹¹ í•¨ìˆ˜ê°€ í˜¸ì¶œë  ë•Œë§ˆë‹¤ ë‹¤ìŒ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ `Langfuse` ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤:\n",
    "- ì…ë ¥ (Input): í•¨ìˆ˜ì— ì „ë‹¬ëœ ëª¨ë“  ì¸ì\n",
    "- ì¶œë ¥ (Output): í•¨ìˆ˜ê°€ ë°˜í™˜í•œ ê²°ê³¼ê°’\n",
    "- ì„±ëŠ¥ (Performance): í•¨ìˆ˜ì˜ ì‹¤í–‰ ì‹œê°„ (Latency)\n",
    "- ì—ëŸ¬ (Errors): í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ë°œìƒí•œ ì˜ˆì™¸(Exception) ì •ë³´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse, observe, get_client\n",
    "\n",
    "# Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "# ì´ í´ë¼ì´ì–¸íŠ¸ëŠ” ì„¤ì •ëœ í™˜ê²½ ë³€ìˆ˜ë¥¼ ìë™ìœ¼ë¡œ ì½ì–´ ì„œë²„ì™€ ì—°ê²°í•©ë‹ˆë‹¤.\n",
    "langfuse = Langfuse()\n",
    "\n",
    "langfuse.auth_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_decorator_code"
   },
   "outputs": [],
   "source": [
    "@observe()\n",
    "def simple_calculator(a: int, b: int, operation: str = \"add\") -> int:\n",
    "    \"\"\"ë‘ ê°œì˜ ì •ìˆ˜ë¥¼ ë°›ì•„ ê°„ë‹¨í•œ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    if operation == \"add\":\n",
    "        return a + b\n",
    "    elif operation == \"subtract\":\n",
    "        return a - b\n",
    "    else:\n",
    "        raise ValueError(\"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì—°ì‚°ì…ë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# 1. ì„±ê³µ ì¼€ì´ìŠ¤ ì‹¤í–‰\n",
    "result_add = simple_calculator(10, 5, operation=\"add\")\n",
    "print(f\"  - ê²°ê³¼: {result_add}\")\n",
    "\n",
    "# 2. ì‹¤íŒ¨ ì¼€ì´ìŠ¤ ì‹¤í–‰ (ì—ëŸ¬ ì¶”ì )\n",
    "try:\n",
    "    simple_calculator(10, 5, operation=\"multiply\")\n",
    "except ValueError as e:\n",
    "    print(f\"  - ì˜ˆìƒëœ ì—ëŸ¬ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_decorator_verify_md"
   },
   "source": [
    "#### Langfuse ëŒ€ì‹œë³´ë“œ í™•ì¸ (Action Item)\n",
    "\n",
    "1.  Langfuse Cloud ([https://cloud.langfuse.com/](https://cloud.langfuse.com/)) ë¡œ ì´ë™í•˜ì—¬ ì—¬ëŸ¬ë¶„ì˜ í”„ë¡œì íŠ¸ì— ì ‘ì†í•˜ì„¸ìš”.\n",
    "2.  ì™¼ìª½ ë©”ë‰´ì—ì„œ 'Traceing'ì„ í´ë¦­í•©ë‹ˆë‹¤.\n",
    "3.  ë°©ê¸ˆ ì‹¤í–‰í•œ `simple_calculator`ë¼ëŠ” ì´ë¦„ì˜ ìƒˆë¡œìš´ Traceê°€ ë‘ ê°œ ìƒì„±ëœ ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤. (ì„±ê³µ ì¼€ì´ìŠ¤ 1ê°œ, ì‹¤íŒ¨ ì¼€ì´ìŠ¤ 1ê°œ)\n",
    "4.  ê° Traceë¥¼ í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”:\n",
    "    - Input/Output: í•¨ìˆ˜ì— ì „ë‹¬ëœ ì¸ìì™€ ë°˜í™˜ê°’ì´ ì •í™•íˆ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    - Error: ì‹¤íŒ¨í•œ Traceì˜ ê²½ìš°, 'Error' íƒ­ì— `ValueError` ì •ë³´ê°€ ìƒì„¸íˆ ê¸°ë¡ëœ ê²ƒì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "    - Latency: ê° Traceì˜ ì‹¤í–‰ ì‹œê°„ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_callback_intro_md"
   },
   "source": [
    "### 2. LangChainì˜ 'ì‹ ê²½ë§' ì¶”ì í•˜ê¸°: `CallbackHandler`\n",
    "\n",
    "Part 1ì—ì„œ ì‚¬ìš©í•œ `@observe()` ë°ì½”ë ˆì´í„°ëŠ” ì¼ë°˜ Python í•¨ìˆ˜ë¥¼ ì¶”ì í•˜ëŠ” ë°ëŠ” ìœ ìš©í•˜ì§€ë§Œ, LLM í˜¸ì¶œì˜ í’ë¶€í•œ ë©”íƒ€ë°ì´í„°(í† í° ì‚¬ìš©ëŸ‰, ëª¨ë¸ íŒŒë¼ë¯¸í„°, ë¹„ìš© ë“±)ë¥¼ ìë™ìœ¼ë¡œ ìº¡ì²˜í•˜ì§€ëŠ” ëª»í•©ë‹ˆë‹¤. ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ `Langfuse`ëŠ” `LangChain`ì˜ ì‹¤í–‰ ë¼ì´í”„ì‚¬ì´í´ì— ì§ì ‘ ì—°ê²°ë˜ëŠ” `CallbackHandler`ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\n",
    "  \n",
    "ì´ í•¸ë“¤ëŸ¬ëŠ” LangChain ì²´ì¸ì´ ì‹¤í–‰ë˜ëŠ” ë™ì•ˆ ë°œìƒí•˜ëŠ” ëª¨ë“  ë‚´ë¶€ ì´ë²¤íŠ¸(`on_llm_start`, `on_llm_end`, `on_chain_start` ë“±)ë¥¼ ê°ì§€í•˜ì—¬, LLM í˜¸ì¶œê³¼ ê´€ë ¨ëœ ìƒì„¸ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ `Langfuse`ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. Langfuse ì½œë°± í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”\n",
    "# í•¸ë“¤ëŸ¬ë¥¼ ì´ˆê¸°í™”í•  ë•Œ, session_idë‚˜ user_idì™€ ê°™ì€ ë©”íƒ€ë°ì´í„°ë¥¼ ì „ë‹¬í•˜ì—¬\n",
    "# Traceë¥¼ ê·¸ë£¹í™”í•˜ê³  í•„í„°ë§í•˜ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "langfuse_handler = CallbackHandler()\n",
    "langfuse_handler.session_id = \"my-first-llm-session\"\n",
    "langfuse_handler.user_id = \"samsung-dx-researcher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_callback_setup_code"
   },
   "outputs": [],
   "source": [
    "# 2. LangChain êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™”\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì°½ì˜ì ì´ê³  ìƒì„¸í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 3. LCEL(LangChain Expression Language)ì„ ì‚¬ìš©í•œ ì²´ì¸ êµ¬ì„±\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_callback_invoke_md"
   },
   "source": [
    "#### LangChain ì²´ì¸ ì‹¤í–‰ ë° ìë™ ì¶”ì \n",
    "\n",
    "ì´ì œ êµ¬ì„±ëœ ì²´ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œ í•µì‹¬ì€ `.invoke()` ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•  ë•Œ `config` ë”•ì…”ë„ˆë¦¬ì— ìš°ë¦¬ê°€ ë§Œë“  `langfuse_handler`ë¥¼ `callbacks` ë¦¬ìŠ¤íŠ¸ì— ë‹´ì•„ ì „ë‹¬í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ ê°„ë‹¨í•œ ì‘ì—…ë§Œìœ¼ë¡œ, LangChainì€ ì²´ì¸ ì‹¤í–‰ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ Langfuse í•¸ë“¤ëŸ¬ì—ê²Œ ìë™ìœ¼ë¡œ ì•Œë ¤ì£¼ê³ , í•¸ë“¤ëŸ¬ëŠ” ì´ ì •ë³´ë¥¼ `Langfuse` ì„œë²„ë¡œ ì „ì†¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZPSiReLUX98"
   },
   "outputs": [],
   "source": [
    "@observe()\n",
    "def run_langchain_with_trace():\n",
    "    print(\"--- LangChain ì²´ì¸ ì‹¤í–‰ ë° Langfuse Tracing ì‹œì‘ ---\")\n",
    "\n",
    "    user_question = \"ì¸ê³µì§€ëŠ¥ ì—ì´ì „íŠ¸ì˜ ë¯¸ë˜ì— ëŒ€í•´ ê°€ì¥ í¥ë¯¸ë¡œìš´ ì‘ìš© ë¶„ì•¼ 3ê°€ì§€ë¥¼ ì•Œë ¤ì¤˜.\"\n",
    "\n",
    "    # CallbackHandler ì´ˆê¸°í™”\n",
    "    langfuse_handler = CallbackHandler()\n",
    "\n",
    "    # configì— ì½œë°± í•¸ë“¤ëŸ¬ë¥¼ ì „ë‹¬í•˜ì—¬ ì²´ì¸ ì‹¤í–‰\n",
    "    response = chain.invoke({\"input\": user_question}, config={\"callbacks\": [langfuse_handler]})\n",
    "\n",
    "    print(\"\\n--- LLM ì‘ë‹µ ---\")\n",
    "    print(response)\n",
    "\n",
    "    # @observe() ë°ì½”ë ˆì´í„°ê°€ ìˆì–´ì•¼ current trace URLì„ ê°€ì ¸ì˜¬ ìˆ˜ ìˆìŒ\n",
    "    langfuse = get_client()\n",
    "    trace_url = langfuse.get_trace_url()\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(f\"ì²´ì¸ ì‹¤í–‰ ì™„ë£Œ - ì•„ë˜ URLì—ì„œ ìƒì„¸í•œ Traceë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\")\n",
    "    print(trace_url)\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "run_langchain_with_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_callback_analysis_md"
   },
   "source": [
    "#### Langfuse ëŒ€ì‹œë³´ë“œ ì‹¬ì¸µ ë¶„ì„ (Action Item)\n",
    "\n",
    "1. ìœ„ì—ì„œ ì¶œë ¥ëœ Trace URLì„ í´ë¦­í•˜ì—¬ `Langfuse` ëŒ€ì‹œë³´ë“œë¡œ ì´ë™í•˜ì„¸ìš”.\n",
    "2. ì´ë²ˆ TraceëŠ” Part 1ì˜ ê²ƒê³¼ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ ìœ ì‹¬íˆ í™•ì¸í•´ë´…ì‹œë‹¤.\n",
    "    - Traceê°€ ë” ì´ìƒ ë‹¨ì¼ `Span`ì´ ì•„ë‹™ë‹ˆë‹¤. ì „ì²´ ì²´ì¸ ì‹¤í–‰(`langchain-google-genai-run`)ì„ ë‚˜íƒ€ë‚´ëŠ” ë¶€ëª¨(Parent) Traceì™€, ê·¸ ì•ˆì—ì„œ ì‹¤ì œ LLM í˜¸ì¶œì´ ì¼ì–´ë‚œ ìì‹(Child) Generationìœ¼ë¡œ êµ¬ì„±ëœ ê³„ì¸µ êµ¬ì¡°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    - `ChatGoogleGenerativeAI`ì„ í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”.\n",
    "        - Model: `gemini-2.5-pro`ì™€ ê°™ì´ ì‚¬ìš©ëœ ëª¨ë¸ ì´ë¦„ì´ ìë™ìœ¼ë¡œ ê¸°ë¡ë©ë‹ˆë‹¤.\n",
    "        - Prompt & Completion: LLMì— ì „ë‹¬ëœ ì „ì²´ í”„ë¡¬í”„íŠ¸ì™€ LLMì´ ìƒì„±í•œ ìµœì¢… ê²°ê³¼ë¬¼ì´ êµ¬ë¶„ë˜ì–´ í‘œì‹œë©ë‹ˆë‹¤.\n",
    "        - Usage & Cost: ì…ë ¥/ì¶œë ¥ í† í° ìˆ˜ì™€, Langfuseê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•œ ì˜ˆìƒ ë¹„ìš©ì´ í‘œì‹œë©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” Agentì˜ ìš´ì˜ ë¹„ìš©ì„ ì •ëŸ‰ì ìœ¼ë¡œ ì¶”ì í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    - ì„¸ì…˜ ë° ì‚¬ìš©ì ì •ë³´: Trace ìƒì„¸ ì •ë³´ì˜ ìƒë‹¨ì—ì„œ, ìš°ë¦¬ê°€ í•¸ë“¤ëŸ¬ì— ì„¤ì •í–ˆë˜ `Session ID`ì™€ `User ID`ê°€ ì˜¬ë°”ë¥´ê²Œ íƒœê¹…(Tagging)ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ì´ë¥¼ í†µí•´ ë‚˜ì¤‘ì— íŠ¹ì • ì‚¬ìš©ìë‚˜ ì„¸ì…˜ì˜ ëª¨ë“  í™œë™ì„ í•„í„°ë§í•˜ì—¬ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_manual_intro_md"
   },
   "source": [
    "### 3. ìˆ˜ë™ ì œì–´ë¥¼ í†µí•œ ì‹¬ì¸µ ì¶”ì : `Spans`ì™€ `Metadata`\n",
    "\n",
    "ìë™ ì¶”ì ì€ í¸ë¦¬í•˜ì§€ë§Œ, ë•Œë¡œëŠ” LLM í˜¸ì¶œ ì™¸ì˜ ì¤‘ìš”í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§(ì˜ˆ: ë°ì´í„° ì „ì²˜ë¦¬, Tool ì‹¤í–‰, ê²°ê³¼ í›„ì²˜ë¦¬)ì˜ ì„±ëŠ¥ê³¼ ë‚´ìš©ì„ ì¶”ì í•˜ê³  ì‹¶ì„ ë•Œê°€ ìˆìŠµë‹ˆë‹¤. `Langfuse`ëŠ” ê°œë°œìê°€ ì§ì ‘ Trace ë‚´ë¶€ì— 'Span'ì´ë¼ëŠ” ì‘ì—… ë‹¨ìœ„ë¥¼ ìƒì„±í•˜ì—¬, ì›Œí¬í”Œë¡œìš°ì˜ ëª¨ë“  ë‹¨ê³„ë¥¼ ìˆ˜ë™ìœ¼ë¡œ, ê·¸ë¦¬ê³  ê³„ì¸µì ìœ¼ë¡œ ì¶”ì í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ë„ ì œê³µí•©ë‹ˆë‹¤.\n",
    "\n",
    "- `langfuse.trace()`: ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì Trace ê°ì²´ë¥¼ ìƒì„±í•˜ê³  ìˆ˜ë™ìœ¼ë¡œ spanì„ ì¶”ê°€í•˜ì—¬ Traceì˜ ìƒì„±ê³¼ ì¢…ë£Œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤.\n",
    "- `trace.span()`: Trace ë‚´ë¶€ì— ì¤‘ì²©ëœ ì‘ì—… ë‹¨ìœ„(Span)ë¥¼ ìƒì„±í•˜ì—¬, ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ë…¼ë¦¬ì ì¸ ë‹¨ê³„ë¡œ ë‚˜ëˆ„ì–´ ì¶”ì í•©ë‹ˆë‹¤.\n",
    "- `metadata` ì™€ `tags`: Traceì™€ Spanì— ì»¤ìŠ¤í…€ ë©”íƒ€ë°ì´í„°(e.g., `prompt_version: 'v2'`)ì™€ íƒœê·¸(e.g., `'rag'`, `'summarization'`)ë¥¼ ì¶”ê°€í•˜ì—¬, ë‚˜ì¤‘ì— ìˆ˜ë§ì€ Traceë¥¼ ì‰½ê²Œ ê²€ìƒ‰í•˜ê³  í•„í„°ë§í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from langfuse import get_client\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# Langfuse í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°\n",
    "langfuse = get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_manual_code"
   },
   "outputs": [],
   "source": [
    "def get_rag_answer(query: str):\n",
    "    \"\"\"ê°„ë‹¨í•œ RAG íŒŒì´í”„ë¼ì¸ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ , ê° ë‹¨ê³„ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì¶”ì í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "\n",
    "    # 1. ìµœìƒìœ„ Trace ìƒì„±: start_as_current_span ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì‚¬ìš©\n",
    "    with langfuse.start_as_current_span(name=\"rag_pipeline\", input={\"query\": query}) as root_span:\n",
    "        # íŠ¸ë ˆì´ìŠ¤ ë©”íƒ€ë°ì´í„° ì„¤ì •\n",
    "        root_span.update_trace(\n",
    "            user_id=\"samsung-dx-researcher\",\n",
    "            session_id=\"rag-session-001\",\n",
    "            metadata={\"prompt_version\": \"v1.2\", \"retriever_type\": \"basic\"},\n",
    "            tags=[\"rag\", \"production\"],\n",
    "        )\n",
    "\n",
    "        # 2. ì²« ë²ˆì§¸ Span: ì¿¼ë¦¬ ì „ì²˜ë¦¬\n",
    "        print(\"--- [Step 1] ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì¤‘... ---\")\n",
    "        with langfuse.start_as_current_span(name=\"step_1_preprocess_query\", input={\"query\": query}) as span_1:\n",
    "            time.sleep(0.5)\n",
    "            processed_query = query.lower().strip() + \" AI ì—ì´ì „íŠ¸\"\n",
    "            span_1.update(output={\"processed_query\": processed_query})\n",
    "\n",
    "        # 3. ë‘ ë²ˆì§¸ Span: ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ (ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¬¸ì„œê°€ íšŒìˆ˜ë˜ëŠ” ê³¼ì •ì„ ì‹œë®¬ë ˆì´ì…˜)\n",
    "        print(\"--- [Step 2] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘... ---\")\n",
    "        with langfuse.start_as_current_span(\n",
    "            name=\"step_2_retrieve_documents\", input={\"query\": processed_query}\n",
    "        ) as span_2:\n",
    "            time.sleep(1)\n",
    "            retrieved_docs = [\n",
    "                \"LangGraphëŠ” ë™ì ì¸ ì œì–´ íë¦„ì„ ë§Œë“œëŠ” ë° ê°•ì ì´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "                \"CrewAIëŠ” ë¹ ë¥´ê²Œ Multi-Agent íŒ€ì„ êµ¬ì„±í•˜ëŠ” ë° íŠ¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\",\n",
    "            ]\n",
    "            span_2.update(output={\"documents_found\": len(retrieved_docs)})\n",
    "\n",
    "        # 4. ì„¸ ë²ˆì§¸ Span: LLMì„ ì‚¬ìš©í•œ ìµœì¢… ë‹µë³€ ìƒì„± (Generation)\n",
    "        print(\"--- [Step 3] LLMìœ¼ë¡œ ìµœì¢… ë‹µë³€ ìƒì„± ì¤‘... ---\")\n",
    "        with langfuse.start_as_current_generation(\n",
    "            name=\"step_3_generate_answer\", model=\"gemini-2.5-flash\"\n",
    "        ) as generation:\n",
    "            context = \"\\n\".join(retrieved_docs)\n",
    "            prompt = f\"ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ '{query}'ì— ëŒ€í•´ í•œ ë¬¸ì¥ìœ¼ë¡œ ë‹µë³€í•´ì¤˜: {context}\"\n",
    "\n",
    "            # LLM í˜¸ì¶œ (ì´ì „ íŒŒíŠ¸ì˜ llm ê°ì²´ ì‚¬ìš©)\n",
    "            response = llm.invoke(prompt)\n",
    "            final_answer = response.content\n",
    "\n",
    "            # Generation ì—…ë°ì´íŠ¸\n",
    "            generation.update(\n",
    "                input=prompt, output=final_answer, usage=response.response_metadata.get(\"token_usage\", {})\n",
    "            )\n",
    "\n",
    "        # ìµœì¢… ê²°ê³¼ë¥¼ root spanì— ê¸°ë¡\n",
    "        root_span.update(output={\"final_answer\": final_answer})\n",
    "\n",
    "        return final_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rag_answer = get_rag_answer(\"LangGraphì™€ CrewAIì˜ ì°¨ì´ì \")\n",
    "print(f\"\\n--- ìµœì¢… ë‹µë³€ ---\\n{final_rag_answer}\")\n",
    "\n",
    "print(f\"\\nì‹¤í–‰ ì™„ë£Œ\")\n",
    "\n",
    "# Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ê³„ì¸µì ìœ¼ë¡œ êµ¬ì„±ëœ 'rag_pipeline' Traceë¥¼ í™•ì¸í•´ë³´ì„¸ìš”.\n",
    "\n",
    "# ì§§ì€ ìƒëª…ì£¼ê¸° ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” flush í˜¸ì¶œ í•„ìš”\n",
    "langfuse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_score_intro_md"
   },
   "source": [
    "### 4. ê²°ê³¼ í‰ê°€ ë° í’ˆì§ˆ ê´€ë¦¬: `Scores`\n",
    "\n",
    "Agentì˜ ì‹¤í–‰ ê³¼ì •ì„ ì¶”ì í•˜ëŠ” ê²ƒë§Œìœ¼ë¡œëŠ” ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ê·¸ ê²°ê³¼ë¬¼ì´ ì–¼ë§ˆë‚˜ 'ì¢‹ì€ì§€'ë¥¼ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•˜ê³ , ì´ í‰ê°€ ê¸°ë¡ì„ ì¶”ì  ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥í•´ì•¼ í•©ë‹ˆë‹¤. `Langfuse`ì˜ `Score` ê¸°ëŠ¥ì€ ë°”ë¡œ ì´ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_llm_judge_md"
   },
   "source": [
    "#### 4.1. LLM-as-a-Judge: LLMì„ ì´ìš©í•œ ìë™ í‰ê°€\n",
    "\n",
    "ìˆ˜ì²œ, ìˆ˜ë§Œ ê±´ì˜ Agent ì‘ë‹µì„ ì‚¬ëŒì´ ì¼ì¼ì´ í‰ê°€í•˜ëŠ” ê²ƒì€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. LLM-as-a-JudgeëŠ” ì´ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, í‰ê°€ì ì—­í• ì„ í•˜ëŠ” ë˜ ë‹¤ë¥¸ LLMì„ ì‚¬ìš©í•˜ì—¬ Agentì˜ ì‘ë‹µ í’ˆì§ˆì„ ìë™ìœ¼ë¡œ ì±„ì í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤.\n",
    "\n",
    "`instructor`ì™€ `Pydantic`ì„ í™œìš©í•˜ì—¬, í‰ê°€ì LLMì´ ì¼ê´€ëœ í˜•ì‹ìœ¼ë¡œ í‰ê°€ ì ìˆ˜ì™€ ê·¼ê±°ë¥¼ ë°˜í™˜í•˜ë„ë¡ ë§Œë“¤ê³ , ê·¸ ê²°ê³¼ë¥¼ `Langfuse`ì˜ `Score`ë¡œ ê¸°ë¡í•˜ëŠ” ìë™í™”ëœ í‰ê°€ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import get_client, observe\n",
    "import instructor\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langfuse.langchain import CallbackHandler\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Langfuse í´ë¼ì´ì–¸íŠ¸ ë° LLM ì´ˆê¸°í™”\n",
    "langfuse = get_client()\n",
    "\n",
    "# ìµœì‹  instructor API ì‚¬ìš© - from_provider ë°©ì‹\n",
    "evaluator_llm_client = instructor.from_provider(\n",
    "    \"google/gemini-2.5-flash-lite\", api_key=os.environ.get(\"GOOGLE_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. í‰ê°€ ê²°ê³¼ë¥¼ ë‹´ì„ Pydantic ëª¨ë¸ ---\n",
    "class EvaluationResult(BaseModel):\n",
    "    score: float = Field(description=\"í‰ê°€ ê¸°ì¤€ì— ë”°ë¥¸ ì ìˆ˜ (0.0 ~ 1.0)\")\n",
    "    reasoning: str = Field(description=\"ì ìˆ˜ë¥¼ ë§¤ê¸´ ì´ìœ ì— ëŒ€í•œ ìƒì„¸í•œ ì„¤ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. LLM-as-a-Judge í•¨ìˆ˜ ---\n",
    "def evaluate_answer_with_llm(question: str, answer: str) -> EvaluationResult:\n",
    "    \"\"\"LLMì„ ì‚¬ìš©í•˜ì—¬ Agentì˜ ë‹µë³€ì„ í‰ê°€í•˜ê³ , ì ìˆ˜ì™€ ê·¼ê±°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.\"\"\"\n",
    "    prompt = f\"\"\"ë‹¹ì‹ ì€ ì—„ê²©í•œ í’ˆì§ˆ í‰ê°€ìì…ë‹ˆë‹¤.\n",
    "    ë‹¤ìŒ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ë³´ê³ , ë‹µë³€ì´ ì–¼ë§ˆë‚˜ ì§ˆë¬¸ì˜ ì˜ë„ë¥¼ ì˜ íŒŒì•…í•˜ê³ , ëª…í™•í•˜ë©°, ìœ ìš©í•œ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.\n",
    "    ì ìˆ˜ëŠ” 0.0(ë§¤ìš° ë‚˜ì¨)ë¶€í„° 1.0(ë§¤ìš° ì¢‹ìŒ)ê¹Œì§€ ë§¤ê²¨ì£¼ì„¸ìš”.\n",
    "\n",
    "    ì§ˆë¬¸: {question}\n",
    "    ë‹µë³€: {answer}\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation = evaluator_llm_client.chat.completions.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}], response_model=EvaluationResult\n",
    "    )\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langfuse_score_code"
   },
   "outputs": [],
   "source": [
    "# --- 3. í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ---\n",
    "@observe()\n",
    "def run_and_evaluate_agent():\n",
    "    print(\"--- LangChain ì²´ì¸ ì‹¤í–‰ ë° ìë™ í‰ê°€ ì‹œì‘ ---\")\n",
    "\n",
    "    # (1) ì—ì´ì „íŠ¸ ì‹¤í–‰ (ì´ì „ íŒŒíŠ¸ì˜ LangChain ì²´ì¸ ì¬ì‚¬ìš©)\n",
    "    handler = CallbackHandler()\n",
    "\n",
    "    user_question = \"AI ì—ì´ì „íŠ¸ ê¸°ìˆ ì˜ ê°€ì¥ í° ë„ì „ ê³¼ì œëŠ” ë¬´ì—‡ì¸ê°€ìš”?\"\n",
    "    agent_answer = chain.invoke({\"input\": user_question}, config={\"callbacks\": [handler]})\n",
    "\n",
    "    print(f\"\\n--- Agent ë‹µë³€ ---\\n{agent_answer}\")\n",
    "\n",
    "    # (2) LLM-as-a-Judgeë¥¼ í†µí•œ ìë™ í‰ê°€\n",
    "    print(\"\\n--- ğŸ¤– LLMìœ¼ë¡œ ìë™ í‰ê°€ ì¤‘... ---\")\n",
    "    evaluation = evaluate_answer_with_llm(user_question, agent_answer)\n",
    "    print(f\"  - ì ìˆ˜: {evaluation.score}\")\n",
    "    print(f\"  - í‰ê°€ ì´ìœ : {evaluation.reasoning}\")\n",
    "\n",
    "    # (3) í‰ê°€ ê²°ê³¼ë¥¼ Langfuse Scoreë¡œ ê¸°ë¡\n",
    "    # @observe() ë°ì½”ë ˆì´í„°ê°€ ìˆì–´ì•¼ current traceë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ\n",
    "    langfuse = get_client()\n",
    "\n",
    "    # í˜„ì¬ traceì— score ì¶”ê°€\n",
    "    langfuse.score_current_trace(name=\"llm-judge-clarity\", value=evaluation.score, comment=evaluation.reasoning)\n",
    "\n",
    "    # trace URL ê°€ì ¸ì˜¤ê¸°\n",
    "    trace_url = langfuse.get_trace_url()\n",
    "\n",
    "    print(f\"\\nâœ… í‰ê°€ ê²°ê³¼ê°€ Langfuseì— Scoreë¡œ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    print(f\"   Trace URL: {trace_url}\")\n",
    "\n",
    "    return agent_answer\n",
    "\n",
    "\n",
    "# í•¨ìˆ˜ ì‹¤í–‰\n",
    "run_and_evaluate_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langfuse_score_verify_md"
   },
   "source": [
    "#### Langfuse ëŒ€ì‹œë³´ë“œ í™•ì¸ (Action item)\n",
    "\n",
    "1.  ìœ„ì—ì„œ ì¶œë ¥ëœ Trace URLì„ í´ë¦­í•˜ì—¬ `Langfuse` ëŒ€ì‹œë³´ë“œë¡œ ì´ë™í•˜ì„¸ìš”.\n",
    "2.  Trace ìƒì„¸ í˜ì´ì§€ì˜ íƒ­ì—ì„œ 'Scores' ì„¹ì…˜ì„ í™•ì¸í•˜ì„¸ìš”.\n",
    "3.  `llm-judge-clarity`ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ, ìš°ë¦¬ê°€ LLMì„ í†µí•´ ìë™ìœ¼ë¡œ ë§¤ê¸´ ì ìˆ˜ì™€ í‰ê°€ ì´ìœ ê°€ ê¸°ë¡ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "4.  (ì‹¬í™”) ì™¼ìª½ ë©”ë‰´ì˜ 'Scores' íƒ­ìœ¼ë¡œ ì´ë™í•˜ë©´, í”„ë¡œì íŠ¸ì˜ ëª¨ë“  Traceì— ëŒ€í•´ ë§¤ê²¨ì§„ ì ìˆ˜ë“¤ì„ ëª¨ì•„ì„œ ë³´ê±°ë‚˜, íŠ¹ì • í‰ê°€ ì§€í‘œ(`name`)ì— ëŒ€í•œ í‰ê·  ì ìˆ˜ë‚˜ ì ìˆ˜ ë¶„í¬ë¥¼ ë¶„ì„í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsy4-ExvJeX5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
