{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_intro_md"
   },
   "source": [
    "# LangFuse + MAS\n",
    "\n",
    "### ì‹¤ìŠµ ëª©í‘œ\n",
    "4ì¼ì°¨ì— ì™„ì„±í•œ  'A2A í†µí•© ì‹œìŠ¤í…œ' ì „ì²´ì— `Langfuse`ë¥¼ ì´ìš©í•œ ì—”ë“œíˆ¬ì—”ë“œ(End-to-End) ê´€ì¸¡ ê°€ëŠ¥ì„±ì„ ë¶€ì—¬í•©ë‹ˆë‹¤. ë‹¨ í•œ ë²ˆì˜ ì‚¬ìš©ì ìš”ì²­ì´ ì–´ë–»ê²Œ ì—¬ëŸ¬ Agent ì‹œìŠ¤í…œë“¤ì„ ê±°ì³ ìµœì¢… ê²°ê³¼ë¬¼ë¡œ ì™„ì„±ë˜ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "1.  ë…ë¦½ì  ì‹¤í–‰ í™˜ê²½ êµ¬ì¶•: `%%writefile`ì„ ì‚¬ìš©í•˜ì—¬ 4ì¼ì°¨ì— ë§Œë“¤ì—ˆë˜ êµ¬ì„± ìš”ì†Œâ€”MCP ì„œë²„, A2A ê²Œì´íŠ¸ì›¨ì´, ê° ì „ë¬¸ê°€ ì„œë¹„ìŠ¤ ëª¨ë“ˆâ€”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "2.  ì‹œìŠ¤í…œ êµ¬ì„± ìš”ì†Œ ê²€í† : ê° ëª¨ë“ˆ(MCP Tool, A2A í”„ë¡œí† ì½œ, ì „ë¬¸ê°€ ì„œë¹„ìŠ¤ ë¡œì§)ì˜ ì—­í• ê³¼ ê´€ê³„ë¥¼ ë‹¤ì‹œ í•œë²ˆ ë³µìŠµí•˜ë©°, ì´ì–´ì§ˆ Part 2ì—ì„œ `Langfuse`ë¥¼ ì–´ëŠ ê³„ì¸µì— ì–´ë–»ê²Œ ì£¼ì…í• ì§€ ê³„íší•˜ëŠ” ê¸°ë°˜ì„ ë‹¤ì§‘ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_setup_md"
   },
   "source": [
    "### 0. ì‚¬ì „ ì¤€ë¹„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì „ì²´ API í‚¤ ì„¤ì •\n",
    "5ì¼ì°¨ ì‹¤ìŠµì€ ìƒˆë¡œìš´ ëŸ°íƒ€ì„ í™˜ê²½ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "e2e_install_code"
   },
   "outputs": [],
   "source": [
    "# !pip install fastapi uvicorn python-dotenv nest-asyncio pyngrok aiohttp httpx newsapi-python arxiv tavily-python slowapi langfuse crewai crewai-tools google-adk langchain-google-genai pydantic instructor requests jsonref starlette -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "e2e_api_keys_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "# OpenAI\n",
    "\n",
    "# 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\n",
    "\n",
    "# Gemini\n",
    "\n",
    "# AIzaSyDVYEpxB86k5-Oi2BApqTr47nnGJ0BwkOc\n",
    "\n",
    "# Finnhub\n",
    "\n",
    "# d2ng5rhr01qvm111q850d2ng5rhr01qvm111q85g\n",
    "\n",
    "# Openweather\n",
    "\n",
    "# da81e6f3657c6f5a2a6b687890c2980f\n",
    "\n",
    "# Tavily\n",
    "\n",
    "# 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\n",
    "\n",
    "# Serper\n",
    "\n",
    "# 01b92c3671ae1f19f98d5b9468a3e5674bde070d\n",
    "\n",
    "# Wolfram APP ID\n",
    "\n",
    "# 73Q6KAVRGG\n",
    "\n",
    "# News API\n",
    "\n",
    "# 043054dcda874c1da6fe5a0ec0471f33\n",
    "\n",
    "\n",
    "# LLM ë° ê²€ìƒ‰ Tool í‚¤\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDVYEpxB86k5-Oi2BApqTr47nnGJ0BwkOc\"\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "os.environ[\"NEWS_API_KEY\"] = \"043054dcda874c1da6fe5a0ec0471f33\"\n",
    "\n",
    "# Langfuse í‚¤\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-c4867845-645e-4c69-a40d-14b5faf31e45\"\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-11135925-919c-4df5-baa1-a510de20e4c9\"\n",
    "# Hostì˜ ê²½ìš° í´ë¼ìš°ë“œì˜ êµ­ê°€ë¥¼ í™•ì¸í•˜ì—¬ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\"\n",
    "\n",
    "# ì„œë²„ ì¸ì¦ìš© ë§ˆìŠ¤í„° í‚¤\n",
    "os.environ[\"MASTER_API_KEY\"] = \"samsung-llm-agent-lv4-master-key\"\n",
    "\n",
    "print(\"ëª¨ë“  API í‚¤ê°€ ì„±ê³µì ìœ¼ë¡œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_build_mcp_md"
   },
   "source": [
    "### 1. ì‹œìŠ¤í…œ ì¬êµ¬ì¶• (Part 1): MCP ì„œë²„(ìì› í—ˆë¸Œ) ì½”ë“œ ìƒì„±\n",
    "4ì¼ì°¨ Lab 1ì—ì„œ ì™„ì„±í–ˆë˜ í”„ë¡œë•ì…˜ê¸‰ MCP ì„œë²„ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ `%%writefile`ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤. ì´ëŠ” Tool, ì •ì  ë¦¬ì†ŒìŠ¤, ë³´ì•ˆ, ì•ˆì •ì„± ê¸°ëŠ¥ì„ ëª¨ë‘ í¬í•¨í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "e2e_write_server_tools_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server_tools.py\n",
    "\n",
    "import os\n",
    "from tavily import TavilyClient\n",
    "from newsapi import NewsApiClient\n",
    "import arxiv\n",
    "import json\n",
    "\n",
    "async def web_search(query: str) -> str:\n",
    "    try:\n",
    "        client = TavilyClient(api_key=os.environ['TAVILY_API_KEY'])\n",
    "        response = client.search(query=query, max_results=3, search_depth=\"advanced\")\n",
    "        return json.dumps([{\"title\": obj['title'], \"url\": obj['url'], \"content\": obj['content']} for obj in response['results']], ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Tavily API ì˜¤ë¥˜: {e}\"})\n",
    "\n",
    "async def news_api_search(query: str) -> str:\n",
    "    try:\n",
    "        client = NewsApiClient(api_key=os.environ['NEWS_API_KEY'])\n",
    "        response = client.get_everything(q=query, language='ko', sort_by='relevancy', page_size=3)\n",
    "        if response['status'] == 'ok':\n",
    "            return json.dumps([{\"title\": article['title'], \"url\": article['url'], \"description\": article['description']} for article in response['articles']], ensure_ascii=False)\n",
    "        else:\n",
    "            return json.dumps({\"error\": f\"News API ì˜¤ë¥˜: {response.get('message', 'Unknown error')}\"})\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"News API í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜: {e}\"})\n",
    "\n",
    "async def arxiv_search(query: str) -> str:\n",
    "    try:\n",
    "        client = arxiv.Client()\n",
    "        search = arxiv.Search(query=query, max_results=2, sort_by=arxiv.SortCriterion.Relevance)\n",
    "        results = list(client.results(search))\n",
    "        return json.dumps([{\"title\": result.title, \"authors\": [str(a) for a in result.authors], \"summary\": result.summary, \"pdf_url\": result.pdf_url} for result in results], ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": f\"Arxiv ê²€ìƒ‰ ì˜¤ë¥˜: {e}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "e2e_write_server_resources_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server_resources.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server_resources.py\n",
    "\n",
    "BLOG_TEMPLATES = {\n",
    "    \"tech_analysis\": \"## ì œëª©\\n\\n### 1. ê¸°ìˆ  ê°œìš”\\n\\n### 2. í•µì‹¬ ì‘ë™ ì›ë¦¬\\n\\n### 3. ì¥ë‹¨ì  ë¶„ì„\\n\\n### 4. ì‹¤ë¬´ ì ìš© ì‚¬ë¡€\\n\\n### 5. ê²°ë¡  ë° í–¥í›„ ì „ë§\",\n",
    "    \"product_review\": \"## ì œëª©\\n\\n### 1. ì²«ì¸ìƒ ë° ë””ìì¸\\n\\n### 2. ì£¼ìš” ê¸°ëŠ¥ ë° ì„±ëŠ¥ í…ŒìŠ¤íŠ¸\\n\\n### 3. ì‹¤ì‚¬ìš© í›„ê¸° (ì¥ì /ë‹¨ì )\\n\\n### 4. ì´í‰ ë° ì¶”ì²œ ëŒ€ìƒ\"\n",
    "}\n",
    "\n",
    "STYLE_GUIDES = {\n",
    "    \"default\": \"ë¬¸ì²´: ì „ë¬¸ì ì´ë©´ì„œë„ ëª…í™•í•˜ê²Œ.\\nëŒ€ìƒ ë…ì: ê¸°ìˆ ì— ê´€ì‹¬ ìˆëŠ” ì¼ë°˜ì¸.\\nì–´ì¡°: ê°ê´€ì ì´ê³  ì‚¬ì‹¤ ê¸°ë°˜.\",\n",
    "    \"samsung_newsroom\": \"ë¬¸ì²´: ì‚¼ì„±ì „ì ë‰´ìŠ¤ë£¸ ê³µì‹ í†¤ì•¤ë§¤ë„ˆ.\\nëŒ€ìƒ ë…ì: ì–¸ë¡ ì¸ ë° IT ì—…ê³„ ì¢…ì‚¬ì.\\nì–´ì¡°: ì‹ ë¢°ê°ì„ ì£¼ëŠ” ê³µì‹ì ì¸ ì–´ì¡°.\"\n",
    "}\n",
    "\n",
    "async def get_template(template_id: str):\n",
    "    return BLOG_TEMPLATES.get(template_id, {\"error\": \"Template not found\"})\n",
    "\n",
    "async def get_style_guide(guide_id: str):\n",
    "    return STYLE_GUIDES.get(guide_id, {\"error\": \"Style guide not found\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e2e_write_mcp_server_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_server.py\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, Depends, Security, Request\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from typing import Dict\n",
    "from fastapi.security import APIKeyHeader\n",
    "from slowapi import Limiter, _rate_limit_exceeded_handler\n",
    "from slowapi.util import get_remote_address\n",
    "from slowapi.errors import RateLimitExceeded\n",
    "from server_tools import web_search, news_api_search, arxiv_search\n",
    "from server_resources import get_template, get_style_guide\n",
    "\n",
    "app = FastAPI(title=\"LLM Agent Resource Hub (MCP Server)\", version=\"1.0.0\")\n",
    "limiter = Limiter(key_func=get_remote_address)\n",
    "app.state.limiter = limiter\n",
    "app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n",
    "\n",
    "API_KEY_NAME = \"X-API-Key\"\n",
    "api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)\n",
    "\n",
    "async def get_api_key(api_key: str = Security(api_key_header)):\n",
    "    if api_key == os.environ.get(\"MASTER_API_KEY\"):\n",
    "        return api_key\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid or missing API Key\")\n",
    "\n",
    "class ToolCallRequest(BaseModel):\n",
    "    query: str = Field(..., description=\"Toolì— ì „ë‹¬í•  ê²€ìƒ‰ì–´ ë˜ëŠ” ì…ë ¥ê°’\")\n",
    "\n",
    "@app.get(\"/\", summary=\"ì„œë²„ ìƒíƒœ í™•ì¸\", tags=[\"Status\"])\n",
    "async def read_root():\n",
    "    return {\"status\": \"ok\", \"message\": \"MCP Server is running successfully.\"}\n",
    "\n",
    "\n",
    "@app.post(\"/api/v1/tools/web_search\", summary=\"ì›¹ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ)\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "async def prod_web_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await web_search(data.query)\n",
    "    return {\"tool\": \"web_search\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.post(\"/api/v1/tools/news_api\", summary=\"ë‰´ìŠ¤ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ)\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "async def prod_news_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await news_api_search(data.query)\n",
    "    return {\"tool\": \"news_api\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.post(\"/api/v1/tools/arxiv_search\", summary=\"ë…¼ë¬¸ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ)\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "async def prod_arxiv_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await arxiv_search(data.query)\n",
    "    return {\"tool\": \"arxiv_search\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.get(\"/api/v1/resources/templates/{template_id}\", summary=\"í…œí”Œë¦¿ ì¡°íšŒ (ë³´ì•ˆ/ì†ë„ì œí•œ)\", tags=[\"Production Resources\"])\n",
    "@limiter.limit(\"60/minute\")\n",
    "async def prod_read_template(request: Request, template_id: str, api_key: str = Depends(get_api_key)):\n",
    "    content = await get_template(template_id)\n",
    "    if isinstance(content, dict) and \"error\" in content:\n",
    "        raise HTTPException(status_code=404, detail=content[\"error\"])\n",
    "    return {\"resource\": \"template\", \"id\": template_id, \"content\": content}\n",
    "\n",
    "print(\"mcp_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_build_a2a_md"
   },
   "source": [
    "### 2. ì‹œìŠ¤í…œ ì¬êµ¬ì¶• (Part 2): A2A ê²Œì´íŠ¸ì›¨ì´ ë° ì„œë¹„ìŠ¤ ëª¨ë“ˆ ì½”ë“œ ìƒì„±\n",
    "ë‹¤ìŒìœ¼ë¡œ, 4ì¼ì°¨ Lab 4ì—ì„œ ì™„ì„±í–ˆë˜ A2A ê²Œì´íŠ¸ì›¨ì´ì˜ ëª¨ë“  êµ¬ì„± ìš”ì†Œë¥¼ `%%writefile`ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì‹œ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "  \n",
    "ì‹¤ìŠµí™˜ê²½ ìƒ A2A ê³µì‹ í”„ë¡œí† ì½œ(Agent card + JSON-RPC 2.0) ëŒ€ì‹  FastAPI ê¸°ë°˜ RESTful API ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e2e_write_a2a_protocol_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting a2a_protocol.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile a2a_protocol.py\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "class DialogueRequest(BaseModel):\n",
    "    session_id: str\n",
    "    user_input: str\n",
    "\n",
    "class DialogueResponse(BaseModel):\n",
    "    session_id: str\n",
    "    agent_response: str\n",
    "    next_action: Optional[Dict[str, Any]] = None\n",
    "\n",
    "class ContentCreationRequest(BaseModel):\n",
    "    topic: str\n",
    "    user_preferences: str\n",
    "\n",
    "class ContentCreationResponse(BaseModel):\n",
    "    draft_content: str\n",
    "    status: str\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "class QualityControlRequest(BaseModel):\n",
    "    topic: str\n",
    "    draft_content: str\n",
    "\n",
    "class QualityControlResponse(BaseModel):\n",
    "    final_post: str\n",
    "    qa_report: Dict[str, Any]\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "e2e_write_mcp_client_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_client.py\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "class MCPClient:\n",
    "    def __init__(self, base_url: str, api_key: str):\n",
    "        if not base_url:\n",
    "            raise ValueError(\"MCP ì„œë²„ì˜ base_urlì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        self.base_url = base_url.rstrip('/')\n",
    "        self.headers = {\"X-API-Key\": api_key, \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    def call_tool(self, tool_name: str, query: str) -> dict:\n",
    "        endpoint = f\"{self.base_url}/api/v1/tools/{tool_name}\"\n",
    "        payload = {\"query\": query}\n",
    "        try:\n",
    "            response = requests.post(endpoint, headers=self.headers, json=payload, timeout=120)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            return {\"error\": f\"HTTP ì˜¤ë¥˜: {e.response.status_code}\", \"detail\": e.response.text}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Tool í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"}\n",
    "\n",
    "    def get_resource(self, resource_type: str, resource_id: str) -> dict:\n",
    "        endpoint = f\"{self.base_url}/api/v1/resources/{resource_type}/{resource_id}\"\n",
    "        try:\n",
    "            response = requests.get(endpoint, headers=self.headers, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            return {\"error\": f\"HTTP ì˜¤ë¥˜: {e.response.status_code}\", \"detail\": e.response.text}\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"ë¦¬ì†ŒìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e2e_write_dialogue_manager_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dialogue_manager_langgraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dialogue_manager_langgraph.py\n",
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "async def handle_dialogue_logic(user_input: str):\n",
    "    print(\"[LangGraph Service] ğŸ§  ëŒ€í™” ê´€ë¦¬ì ì‹¤í–‰ë¨...\")\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0)\n",
    "        prompt = f\"ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ ì£¼ì œë¥¼ 20ë‹¨ì–´ ì´ë‚´ì˜ ê°„ê²°í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ì‚¬ìš©ìì˜ ìˆ¨ê²¨ì§„ ìš”êµ¬ì‚¬í•­(ìŠ¤íƒ€ì¼, í†¤ì•¤ë§¤ë„ˆ ë“±)ì„ ì¶”ë¡ í•´ì¤˜. ê²°ê³¼ëŠ” 'ì£¼ì œ: [ìš”ì•½ëœ ì£¼ì œ]\\nìš”êµ¬ì‚¬í•­: [ì¶”ë¡ ëœ ìš”êµ¬ì‚¬í•­]' í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì¤˜. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆ.\\n\\nì‚¬ìš©ì ìš”ì²­: '{user_input}'\"\n",
    "        response_text = llm.invoke(prompt).content\n",
    "        topic = response_text.split(\"ì£¼ì œ:\")[1].split(\"ìš”êµ¬ì‚¬í•­:\")[0].strip()\n",
    "        preferences = response_text.split(\"ìš”êµ¬ì‚¬í•­:\")[1].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[LangGraph Service] ğŸ”´ LLM í˜¸ì¶œ ì˜¤ë¥˜, Fallback ë¡œì§ ì‚¬ìš©: {e}\")\n",
    "        topic = user_input\n",
    "        preferences = \"ì „ë¬¸ì ì´ë©´ì„œë„ ì‰¬ìš´ ì–´ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    response = {\n",
    "        \"agent_response\": f\"ì•Œê² ìŠµë‹ˆë‹¤. '{topic}'ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ ìƒì„±ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. '{preferences}' ìš”êµ¬ì‚¬í•­ì„ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤.\",\n",
    "        \"next_action\": {\"action\": \"CREATE_CONTENT\", \"topic\": topic, \"user_preferences\": preferences}\n",
    "    }\n",
    "    print(f\"[LangGraph Service] âœ… ë‹¤ìŒ í–‰ë™ ê²°ì •: {response['next_action']}\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "e2e_write_crewai_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting content_creation_crew.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile content_creation_crew.py\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import BaseTool\n",
    "import json\n",
    "from mcp_client import MCPClient\n",
    "\n",
    "class MCPTool(BaseTool):\n",
    "    name: str\n",
    "    description: str\n",
    "    client: MCPClient\n",
    "\n",
    "    def _run(self, query: str) -> str:\n",
    "        print(f\"  [MCP Bridge] CrewAI -> MCP Server: Calling tool '{self.name}' with query '{query}'\")\n",
    "        response = self.client.call_tool(self.name, query)\n",
    "        return json.dumps(response, ensure_ascii=False)\n",
    "\n",
    "def handle_creation_logic(topic: str, user_preferences: str, mcp_client: MCPClient):\n",
    "    print(f\"[CrewAI Service] ğŸ‘¥ ì½˜í…ì¸  ì œì‘íŒ€ ê°€ë™ë¨ (ì£¼ì œ: {topic[:30]}...)\")\n",
    "    try:\n",
    "        crew_web_search = MCPTool(name=\"web_search\", description=\"ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\", client=mcp_client)\n",
    "        crew_arxiv_search = MCPTool(name=\"arxiv_search\", description=\"í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\", client=mcp_client)\n",
    "\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")\n",
    "        researcher = Agent(role=\"ì„ ì„ ë¦¬ì„œì²˜\", goal=f\"{topic}ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„\", backstory=\"ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ê¸°ìˆ  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\", tools=[crew_web_search, crew_arxiv_search], llm=llm, verbose=True)\n",
    "        writer = Agent(role=\"ì „ë¬¸ ì‘ê°€\", goal=\"ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ë¸”ë¡œê·¸ ê¸€ ì‘ì„±\", backstory=\"ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘ê°€ì…ë‹ˆë‹¤.\", llm=llm, verbose=True)\n",
    "\n",
    "        research_task = Task(description=f\"'{topic}'ì— ëŒ€í•´ ì›¹ê³¼ í•™ìˆ  ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\", expected_output=\"êµ¬ì¡°í™”ëœ ë¶„ì„ ë³´ê³ ì„œ\", agent=researcher)\n",
    "        write_task = Task(description=f\"ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, '{user_preferences}' ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•˜ì—¬ ë¸”ë¡œê·¸ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.\", expected_output=\"ì™„ì„±ëœ ë¸”ë¡œê·¸ ì´ˆì•ˆ\", agent=writer, context=[research_task])\n",
    "\n",
    "        crew = Crew(agents=[researcher, writer], tasks=[research_task, write_task], process=Process.sequential)\n",
    "        result = crew.kickoff()\n",
    "        print(\"[CrewAI Service] âœ… ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error_message = f\"CrewAI ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "        print(f\"[CrewAI Service] ğŸ”´ {error_message}\")\n",
    "        return error_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e2e_write_adk_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quality_control_adk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile quality_control_adk.py\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "async def handle_qc_logic(topic: str, draft_content: str):\n",
    "    print(f\"[ADK Service] ğŸ§ í’ˆì§ˆ ê´€ë¦¬íŒ€ ê°€ë™ë¨ (ì£¼ì œ: {topic[:30]}...)\")\n",
    "    try:\n",
    "        qa_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "        prompt = f\"ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ê¸°ìˆ  ë¸”ë¡œê·¸ì˜ ìˆ˜ì„ í¸ì§‘ìì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ˆì•ˆì„ ê²€í† í•˜ê³ , ìš°ë¦¬ ë¸”ë¡œê·¸ì˜ í†¤ì•¤ë§¤ë„ˆ(ì „ë¬¸ì , ì‹ ë¢°ê°, ëª…í™•í•¨)ì— ë§ì¶° ìµœì¢… ë°œí–‰ë³¸ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ: {topic}\\nì´ˆì•ˆ: {draft_content}\"\n",
    "        final_post = qa_llm.invoke(prompt).content\n",
    "        report = {\"seo_score\": 95, \"readability\": \"excellent\", \"final_char_count\": len(final_post), \"status\": \"Approved\"}\n",
    "        print(\"[ADK Service] âœ… ìµœì¢… í¸ì§‘ ë° ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ.\")\n",
    "        return final_post, report\n",
    "    except Exception as e:\n",
    "        error_message = f\"ADK í’ˆì§ˆ ê´€ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "        print(f\"[ADK Service] ğŸ”´ {error_message}\")\n",
    "        return draft_content, {\"status\": \"Failed\", \"error\": error_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "e2e_write_a2a_server_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting a2a_blog_system.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile a2a_blog_system.py\n",
    "\n",
    "from fastapi import FastAPI, Depends, HTTPException, Security\n",
    "from fastapi.security import APIKeyHeader\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Optional\n",
    "from a2a_protocol import *\n",
    "from dialogue_manager_langgraph import handle_dialogue_logic\n",
    "from content_creation_crew import handle_creation_logic, MCPClient\n",
    "from quality_control_adk import handle_qc_logic\n",
    "\n",
    "app = FastAPI(title=\"A2A Integrated Research Blog System\", version=\"1.0.0\")\n",
    "\n",
    "API_KEY_NAME = \"X-API-Key\"\n",
    "api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)\n",
    "\n",
    "async def get_api_key(api_key: str = Security(api_key_header)):\n",
    "    if api_key == os.environ.get(\"MASTER_API_KEY\"):\n",
    "        return api_key\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n",
    "\n",
    "mcp_client: Optional[MCPClient] = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def startup_event():\n",
    "    global mcp_client\n",
    "    mcp_server_url = os.environ.get(\"MCP_SERVER_URL\")\n",
    "    master_key = os.environ.get(\"MASTER_API_KEY\")\n",
    "    if mcp_server_url and master_key:\n",
    "        mcp_client = MCPClient(base_url=mcp_server_url, api_key=master_key)\n",
    "        print(f\"âœ… A2A Gateway: MCP í´ë¼ì´ì–¸íŠ¸ê°€ '{mcp_server_url}'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ A2A Gateway: MCP_SERVER_URL ë˜ëŠ” MASTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "@app.get(\"/\", tags=[\"Status\"])\n",
    "async def root():\n",
    "    return {\"status\": \"ok\", \"message\": \"A2A Gateway is alive\"}\n",
    "\n",
    "@app.post(\"/api/v1/dialogue\", response_model=DialogueResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_dialogue(request: DialogueRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await handle_dialogue_logic(request.user_input)\n",
    "    return DialogueResponse(session_id=request.session_id, result)\n",
    "\n",
    "@app.post(\"/api/v1/create-content\", response_model=ContentCreationResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_content_creation(request: ContentCreationRequest, api_key: str = Depends(get_api_key)):\n",
    "    try:\n",
    "        draft = await asyncio.to_thread(handle_creation_logic, request.topic, request.user_preferences, mcp_client)\n",
    "        return ContentCreationResponse(draft_content=draft, status=\"COMPLETED\")\n",
    "    except Exception as e:\n",
    "        return ContentCreationResponse(draft_content=\"\", status=\"FAILED\", error_message=str(e))\n",
    "\n",
    "@app.post(\"/api/v1/quality-control\", response_model=QualityControlResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_quality_control(request: QualityControlRequest, api_key: str = Depends(get_api_key)):\n",
    "    final_post, report = await handle_qc_logic(request.topic, request.draft_content)\n",
    "    return QualityControlResponse(final_post=final_post, qa_report=report, status=\"COMPLETED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_build_launcher_md"
   },
   "source": [
    "### 3. ì‹œìŠ¤í…œ ì¬êµ¬ì¶• (Part 3): ì„œë²„ ì‹¤í–‰ ìœ í‹¸ë¦¬í‹° ìƒì„±\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, 4ì¼ì°¨ì— ì™„ì„±í–ˆë˜ í™˜ê²½ ê°ì§€í˜• ì„œë²„ ì‹¤í–‰ê¸°ë¥¼ `%%writefile`ì„ ì‚¬ìš©í•˜ì—¬ `server_launcher.py` íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ì˜ ë³µì¡í•œ ì„œë²„ ì‹¤í–‰ ë¡œì§ì„ ëª¨ë“ˆí™”í•˜ê³ , ë©”ì¸ ë…¸íŠ¸ë¶ì„ ê¹”ë”í•˜ê²Œ ìœ ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e2e_write_launcher_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting server_launcher.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile server_launcher.py\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import threading\n",
    "\n",
    "def print_logs(process, name):\n",
    "    \"\"\"ì„œë²„ í”„ë¡œì„¸ìŠ¤ì˜ ë¡œê·¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    # stderrë¥¼ ì‚¬ìš©í•˜ì—¬ uvicornì˜ ë¡œê·¸ë¥¼ ì½ìŠµë‹ˆë‹¤.\n",
    "    for line in iter(process.stderr.readline, ''):\n",
    "        print(f\"[{name} LOG] {line.strip()}\")\n",
    "\n",
    "def launch_fastapi_app(app_module_name: str, port: int):\n",
    "    \"\"\"\n",
    "    FastAPI ì•±ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸš€ {app_module_name} ì„œë²„ë¥¼ ë¡œì»¬ í¬íŠ¸ {port}ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "    # Step 1: ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬\n",
    "    try:\n",
    "        # pkillì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í¬íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” uvicorn í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n",
    "        subprocess.run(['pkill', '-f', f\"uvicorn.*{app_module_name}.*--port {port}\"], capture_output=True)\n",
    "        print(f\"   ğŸ§¹ í¬íŠ¸ {port}ì˜ ê¸°ì¡´ Uvicorn í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        time.sleep(2)\n",
    "    except Exception as e:\n",
    "        print(f\"   â„¹ï¸ í”„ë¡œì„¸ìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë¬´ì‹œ ê°€ëŠ¥): {e}\")\n",
    "\n",
    "    # Step 2: FastAPI ì•±(Uvicorn) ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰\n",
    "    try:\n",
    "        command = [\n",
    "            sys.executable, '-m', 'uvicorn', f\"{app_module_name}:app\",\n",
    "            '--host', '0.0.0.0', '--port', str(port), '--reload'\n",
    "        ]\n",
    "        server_process = subprocess.Popen(\n",
    "            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True, encoding='utf-8'\n",
    "        )\n",
    "        print(f\"   â³ FastAPI ì„œë²„ë¥¼ í¬íŠ¸ {port}ì—ì„œ ì‹œì‘í•˜ëŠ” ì¤‘...\")\n",
    "\n",
    "        # ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ì‹œì‘\n",
    "        log_thread = threading.Thread(target=print_logs, args=(server_process, app_module_name))\n",
    "        log_thread.daemon = True\n",
    "        log_thread.start()\n",
    "        print(\"   ğŸ”Š ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\")\n",
    "        time.sleep(5) # ì„œë²„ê°€ ì™„ì „íˆ ì‹œì‘ë  ë•Œê¹Œì§€ ì ì‹œ ëŒ€ê¸°\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ FastAPI ì„œë²„ ì‹œì‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    # Step 3: ë¡œì»¬ ì£¼ì†Œì™€ í”„ë¡œì„¸ìŠ¤ ë°˜í™˜\n",
    "    local_url = f\"http://localhost:{port}\"\n",
    "    print(f\"âœ… {app_module_name} ì„œë²„ê°€ ë¡œì»¬({local_url})ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    return local_url, server_process\n",
    "\n",
    "print(\"âœ… 'server_launcher.py' íŒŒì¼ì´ [ë¡œì»¬ ì „ìš©]ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6lQDlsMf0tq9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reverse_proxy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reverse_proxy.py\n",
    "\n",
    "from fastapi import FastAPI, Request\n",
    "from fastapi.responses import StreamingResponse\n",
    "import httpx\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "MCP_SERVER_URL = \"http://localhost:8501\"\n",
    "A2A_SERVER_URL = \"http://localhost:8502\"\n",
    "\n",
    "client = httpx.AsyncClient(timeout=300.0)\n",
    "\n",
    "async def proxy_request(target_url: str, request: Request):\n",
    "    \"\"\"\n",
    "    httpxë¥¼ ìŠ¤íŠ¸ë¦¬ë° ëª¨ë“œë¡œ ì‚¬ìš©í•˜ì—¬ ìš”ì²­ì„ ì „ë‹¬í•˜ê³  ì‘ë‹µì„ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” í•¨ìˆ˜.\n",
    "    StreamConsumed ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ client.send(stream=True)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. í´ë¼ì´ì–¸íŠ¸ì˜ ìš”ì²­ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‚´ë¶€ ì„œë²„ë¡œ ë³´ë‚¼ ìš”ì²­ì„ ì¬êµ¬ì„±í•©ë‹ˆë‹¤.\n",
    "    headers = {k: v for k, v in request.headers.items() if k.lower() not in ['host', 'cookie']}\n",
    "\n",
    "    req = client.build_request(\n",
    "        method=request.method,\n",
    "        url=target_url,\n",
    "        headers=headers,\n",
    "        params=request.query_params,\n",
    "        content=await request.body()\n",
    "    )\n",
    "\n",
    "    # 2. stream=True ì˜µì…˜ìœ¼ë¡œ ìš”ì²­ì„ ë³´ë‚´ ì‘ë‹µ ë³¸ë¬¸ì„ ë¯¸ë¦¬ ì½ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    r = await client.send(req, stream=True)\n",
    "\n",
    "    # 3. ë‚´ë¶€ ì„œë²„ì˜ ì‘ë‹µì„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ê·¸ëŒ€ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.\n",
    "    return StreamingResponse(\n",
    "        r.aiter_raw(),\n",
    "        status_code=r.status_code,\n",
    "        headers=r.headers\n",
    "    )\n",
    "\n",
    "@app.api_route(\"/mcp/{path:path}\", methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"])\n",
    "async def route_mcp(path: str, request: Request):\n",
    "    \"\"\" '/mcp'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ìš”ì²­ì„ MCP ì„œë²„(8501)ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. \"\"\"\n",
    "    target_url = f\"{MCP_SERVER_URL}/{path}\"\n",
    "    return await proxy_request(target_url, request)\n",
    "\n",
    "@app.api_route(\"/a2a/{path:path}\", methods=[\"GET\", \"POST\", \"PUT\", \"DELETE\", \"PATCH\"])\n",
    "async def route_a2a(path: str, request: Request):\n",
    "    \"\"\" '/a2a'ë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  ìš”ì²­ì„ A2A Gateway ì„œë²„(8502)ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤. \"\"\"\n",
    "    target_url = f\"{A2A_SERVER_URL}/{path}\"\n",
    "    return await proxy_request(target_url, request)\n",
    "\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Reverse Proxy is running. Use /mcp/ or /a2a/ prefixes.\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EumyrltdvLsR"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_inject_infra_md"
   },
   "source": [
    "### 4. ê´€ì¸¡ ê°€ëŠ¥ì„± ì£¼ì… (Part 1): ì¸í”„ë¼ ê³„ì¸µ ì¶”ì  (MCP ì„œë²„ & A2A ê²Œì´íŠ¸ì›¨ì´)\n",
    "\n",
    "ê°€ì¥ ë¨¼ì €, ìš°ë¦¬ ì‹œìŠ¤í…œì˜ ê°€ì¥ ë°”ê¹¥ìª½ ê²½ê³„ì„ ì´ì ê¸°ë°˜ ì‹œì„¤ì¸ ë‘ ê°œì˜ ì„œë²„ì— ì¶”ì  ê¸°ëŠ¥ì„ ì‹¬ìŠµë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” ì–´ë–¤ ìš”ì²­ì´ ì–¸ì œ ë“¤ì–´ì™”ê³ , ì–´ë–¤ Toolì´ ì–¼ë§ˆë‚˜ ìì£¼ í˜¸ì¶œë˜ëŠ”ì§€ì— ëŒ€í•œ ê±°ì‹œì ì¸ ê·¸ë¦¼ì„ í™•ë³´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "1.  A2A ê²Œì´íŠ¸ì›¨ì´ (`a2a_blog_system.py`): `FastAPI Middleware`ë¥¼ ì‚¬ìš©í•˜ì—¬, ê²Œì´íŠ¸ì›¨ì´ê°€ ë°›ëŠ” ëª¨ë“  API ìš”ì²­/ì‘ë‹µì„ ìë™ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ìµœìƒìœ„ ë¶€ëª¨ Traceë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ê²ƒì´ ëª¨ë“  ë¶„ì„ì˜ ì‹œì‘ì ì´ ë©ë‹ˆë‹¤.\n",
    "2.  MCP ì„œë²„ (`mcp_server.py`): ê° Tool ì—”ë“œí¬ì¸íŠ¸ì— `@observe()` ë°ì½”ë ˆì´í„°ë¥¼ ì¶”ê°€í•˜ì—¬, ì–´ë–¤ ìƒìœ„ Agent(e.g., CrewAI)ê°€ ì–´ë–¤ Toolì„ í˜¸ì¶œí–ˆëŠ”ì§€ ê°œë³„ì ì¸ ìì‹ Traceë¡œ ê¸°ë¡í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "e2e_update_mcp_server_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mcp_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mcp_server.py\n",
    "\n",
    "# --- Imports ---\n",
    "from fastapi import FastAPI, HTTPException, Depends, Security, Request\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "from typing import Dict\n",
    "from fastapi.security import APIKeyHeader\n",
    "from slowapi import Limiter, _rate_limit_exceeded_handler\n",
    "from slowapi.util import get_remote_address\n",
    "from slowapi.errors import RateLimitExceeded\n",
    "from server_tools import web_search, news_api_search, arxiv_search\n",
    "from server_resources import get_template, get_style_guide\n",
    "from langfuse import observe\n",
    "\n",
    "# --- App & Limiter Setup ---\n",
    "app = FastAPI(title=\"LLM Agent Resource Hub (MCP Server)\", version=\"1.0.0\")\n",
    "limiter = Limiter(key_func=get_remote_address)\n",
    "app.state.limiter = limiter\n",
    "app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n",
    "\n",
    "# --- Security Setup ---\n",
    "API_KEY_NAME = \"X-API-Key\"\n",
    "api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)\n",
    "async def get_api_key(api_key: str = Security(api_key_header)):\n",
    "    if api_key == os.environ.get(\"MASTER_API_KEY\"):\n",
    "        return api_key\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid or missing API Key\")\n",
    "\n",
    "# --- Pydantic Models ---\n",
    "class ToolCallRequest(BaseModel):\n",
    "    query: str = Field(..., description=\"Toolì— ì „ë‹¬í•  ê²€ìƒ‰ì–´ ë˜ëŠ” ì…ë ¥ê°’\")\n",
    "\n",
    "# --- Root Endpoint ---\n",
    "@app.get(\"/\", summary=\"ì„œë²„ ìƒíƒœ í™•ì¸\", tags=[\"Status\"])\n",
    "async def read_root():\n",
    "    return {\"status\": \"ok\", \"message\": \"MCP Server is running successfully.\"}\n",
    "\n",
    "# --- Production Endpoints with Langfuse Observability ---\n",
    "@app.post(\"/api/v1/tools/web_search\", summary=\"ì›¹ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ/ì¶”ì )\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "@observe(name=\"mcp-tool-web-search\")\n",
    "async def prod_web_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await web_search(data.query)\n",
    "    return {\"tool\": \"web_search\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.post(\"/api/v1/tools/news_api\", summary=\"ë‰´ìŠ¤ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ/ì¶”ì )\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "@observe(name=\"mcp-tool-news-api\")\n",
    "async def prod_news_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await news_api_search(data.query)\n",
    "    return {\"tool\": \"news_api\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.post(\"/api/v1/tools/arxiv_search\", summary=\"ë…¼ë¬¸ ê²€ìƒ‰ (ë³´ì•ˆ/ì†ë„ì œí•œ/ì¶”ì )\", tags=[\"Production Tools\"])\n",
    "@limiter.limit(\"20/minute\")\n",
    "@observe(name=\"mcp-tool-arxiv-search\")\n",
    "async def prod_arxiv_search(request: Request, data: ToolCallRequest, api_key: str = Depends(get_api_key)):\n",
    "    result = await arxiv_search(data.query)\n",
    "    return {\"tool\": \"arxiv_search\", \"query\": data.query, \"result\": result}\n",
    "\n",
    "@app.get(\"/api/v1/resources/templates/{template_id}\", summary=\"í…œí”Œë¦¿ ì¡°íšŒ (ë³´ì•ˆ/ì†ë„ì œí•œ/ì¶”ì )\", tags=[\"Production Resources\"])\n",
    "@limiter.limit(\"60/minute\")\n",
    "@observe(name=\"mcp-resource-template\")\n",
    "async def prod_read_template(request: Request, template_id: str, api_key: str = Depends(get_api_key)):\n",
    "    content = await get_template(template_id)\n",
    "    if isinstance(content, dict) and \"error\" in content:\n",
    "        raise HTTPException(status_code=404, detail=content[\"error\"])\n",
    "    return {\"resource\": \"template\", \"id\": template_id, \"content\": content}\n",
    "\n",
    "print(\"mcp_server.py íŒŒì¼ì´ Langfuse ì¶”ì  ê¸°ëŠ¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "e2e_update_a2a_server_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting a2a_blog_system.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile a2a_blog_system.py\n",
    "\n",
    "# --- Imports ---\n",
    "from fastapi import FastAPI, Depends, HTTPException, Security\n",
    "from fastapi.security import APIKeyHeader\n",
    "from contextlib import asynccontextmanager\n",
    "import os\n",
    "import asyncio\n",
    "from typing import Optional\n",
    "from a2a_protocol import *\n",
    "from dialogue_manager_langgraph import handle_dialogue_logic\n",
    "from content_creation_crew import handle_creation_logic, MCPClient\n",
    "from quality_control_adk import handle_qc_logic\n",
    "\n",
    "# Langfuse v3 SDK import\n",
    "from langfuse import get_client\n",
    "\n",
    "# Langfuse í´ë¼ì´ì–¸íŠ¸ ì „ì—­ ë³€ìˆ˜\n",
    "langfuse_client = None\n",
    "\n",
    "# --- FastAPI Lifespan ---\n",
    "@asynccontextmanager\n",
    "async def lifespan(app: FastAPI):\n",
    "    global langfuse_client\n",
    "    # Startup: Langfuse í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "    try:\n",
    "        langfuse_client = get_client()\n",
    "        if langfuse_client:\n",
    "            if langfuse_client.auth_check():\n",
    "                print(\"Langfuse í´ë¼ì´ì–¸íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "            else:\n",
    "                print(\"Langfuse ì¸ì¦ ì‹¤íŒ¨\")\n",
    "    except Exception as e:\n",
    "        print(f\"Langfuse ì´ˆê¸°í™” ì‹¤íŒ¨: {e}\")\n",
    "        langfuse_client = None\n",
    "\n",
    "    yield  # ì„œë²„ ì‹¤í–‰\n",
    "\n",
    "    # Shutdown: Langfuse flush\n",
    "    if langfuse_client:\n",
    "        langfuse_client.flush()\n",
    "        print(\"âœ… Langfuse ì´ë²¤íŠ¸ê°€ ëª¨ë‘ ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# --- App & Security Setup ---\n",
    "app = FastAPI(\n",
    "    title=\"A2A Integrated Research Blog System\",\n",
    "    version=\"1.0.0\",\n",
    "    lifespan=lifespan\n",
    ")\n",
    "\n",
    "API_KEY_NAME = \"X-API-Key\"\n",
    "api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)\n",
    "\n",
    "async def get_api_key(api_key: str = Security(api_key_header)):\n",
    "    if api_key == os.environ.get(\"MASTER_API_KEY\"):\n",
    "        return api_key\n",
    "    else:\n",
    "        raise HTTPException(status_code=401, detail=\"Invalid API Key\")\n",
    "\n",
    "# --- MCP Client Setup ---\n",
    "mcp_client: Optional[MCPClient] = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def startup_event():\n",
    "    global mcp_client\n",
    "    mcp_server_url = os.environ.get(\"MCP_SERVER_URL\")\n",
    "    master_key = os.environ.get(\"MASTER_API_KEY\")\n",
    "    if mcp_server_url and master_key:\n",
    "        mcp_client = MCPClient(base_url=mcp_server_url, api_key=master_key)\n",
    "        print(f\"A2A Gateway: MCP í´ë¼ì´ì–¸íŠ¸ê°€ '{mcp_server_url}'ì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"A2A Gateway: MCP_SERVER_URL ë˜ëŠ” MASTER_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# --- Endpoints ---\n",
    "@app.get(\"/\", tags=[\"Status\"])\n",
    "async def root():\n",
    "    return {\"status\": \"ok\", \"message\": \"A2A Gateway is alive\"}\n",
    "\n",
    "@app.post(\"/api/v1/dialogue\", response_model=DialogueResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_dialogue(request: DialogueRequest, api_key: str = Depends(get_api_key)):\n",
    "\n",
    "    if langfuse_client:\n",
    "        with langfuse_client.start_as_current_span(\n",
    "            name=\"dialogue-request\",\n",
    "            input={\n",
    "                \"user_input\": request.user_input,\n",
    "                \"session_id\": request.session_id\n",
    "            }\n",
    "        ) as span:\n",
    "            # íŠ¸ë ˆì´ìŠ¤ ì†ì„± ì„¤ì •\n",
    "            span.update_trace(\n",
    "                session_id=request.session_id,\n",
    "                tags=[\"dialogue\", \"api\"],\n",
    "                metadata={\"endpoint\": \"/api/v1/dialogue\"}\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                result = await handle_dialogue_logic(request.user_input)\n",
    "\n",
    "                # ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "                span.update(output=result)\n",
    "                span.update_trace(output=result)\n",
    "\n",
    "                return DialogueResponse(session_id=request.session_id, **result)\n",
    "\n",
    "            except Exception as e:\n",
    "                span.update(\n",
    "                    output={\"error\": str(e)},\n",
    "                    level=\"ERROR\",\n",
    "                    status_message=f\"Dialogue processing failed: {str(e)}\"\n",
    "                )\n",
    "                raise\n",
    "    else:\n",
    "        # Langfuse ì—†ì´ ì‹¤í–‰\n",
    "        result = await handle_dialogue_logic(request.user_input)\n",
    "        return DialogueResponse(session_id=request.session_id, **result)\n",
    "\n",
    "@app.post(\"/api/v1/create-content\", response_model=ContentCreationResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_content_creation(request: ContentCreationRequest, api_key: str = Depends(get_api_key)):\n",
    "\n",
    "    if langfuse_client:\n",
    "        with langfuse_client.start_as_current_span(\n",
    "            name=\"content-creation-request\",\n",
    "            input={\n",
    "                \"topic\": request.topic,\n",
    "                \"user_preferences\": request.user_preferences\n",
    "            }\n",
    "        ) as span:\n",
    "            # íŠ¸ë ˆì´ìŠ¤ ì†ì„± ì„¤ì •\n",
    "            span.update_trace(\n",
    "                tags=[\"content-creation\", \"api\"],\n",
    "                metadata={\n",
    "                    \"endpoint\": \"/api/v1/create-content\",\n",
    "                    \"topic\": request.topic\n",
    "                }\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                draft = await asyncio.to_thread(\n",
    "                    handle_creation_logic,\n",
    "                    request.topic,\n",
    "                    request.user_preferences,\n",
    "                    mcp_client\n",
    "                )\n",
    "\n",
    "                # ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "                response_data = {\"draft_content\": draft, \"status\": \"COMPLETED\"}\n",
    "                span.update(output=response_data)\n",
    "                span.update_trace(output=response_data)\n",
    "\n",
    "                return ContentCreationResponse(draft_content=draft, status=\"COMPLETED\")\n",
    "\n",
    "            except Exception as e:\n",
    "                error_data = {\"error\": str(e), \"status\": \"FAILED\"}\n",
    "                span.update(\n",
    "                    output=error_data,\n",
    "                    level=\"ERROR\",\n",
    "                    status_message=f\"Content creation failed: {str(e)}\"\n",
    "                )\n",
    "                return ContentCreationResponse(draft_content=\"\", status=\"FAILED\", error_message=str(e))\n",
    "    else:\n",
    "        # Langfuse ì—†ì´ ì‹¤í–‰\n",
    "        try:\n",
    "            draft = await asyncio.to_thread(handle_creation_logic, request.topic, request.user_preferences, mcp_client)\n",
    "            return ContentCreationResponse(draft_content=draft, status=\"COMPLETED\")\n",
    "        except Exception as e:\n",
    "            return ContentCreationResponse(draft_content=\"\", status=\"FAILED\", error_message=str(e))\n",
    "\n",
    "@app.post(\"/api/v1/quality-control\", response_model=QualityControlResponse, tags=[\"A2A Protocol\"])\n",
    "async def handle_quality_control(request: QualityControlRequest, api_key: str = Depends(get_api_key)):\n",
    "\n",
    "    if langfuse_client:\n",
    "        with langfuse_client.start_as_current_span(\n",
    "            name=\"quality-control-request\",\n",
    "            input={\n",
    "                \"topic\": request.topic,\n",
    "                \"draft_content_length\": len(request.draft_content)\n",
    "            }\n",
    "        ) as span:\n",
    "            # íŠ¸ë ˆì´ìŠ¤ ì†ì„± ì„¤ì •\n",
    "            span.update_trace(\n",
    "                tags=[\"quality-control\", \"api\"],\n",
    "                metadata={\n",
    "                    \"endpoint\": \"/api/v1/quality-control\",\n",
    "                    \"topic\": request.topic\n",
    "                }\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                final_post, report = await handle_qc_logic(request.topic, request.draft_content)\n",
    "\n",
    "                # ê²°ê³¼ ì—…ë°ì´íŠ¸\n",
    "                response_data = {\n",
    "                    \"final_post\": final_post,\n",
    "                    \"qa_report\": report,\n",
    "                    \"status\": \"COMPLETED\"\n",
    "                }\n",
    "                span.update(output=response_data)\n",
    "                span.update_trace(output=response_data)\n",
    "\n",
    "                return QualityControlResponse(final_post=final_post, qa_report=report, status=\"COMPLETED\")\n",
    "\n",
    "            except Exception as e:\n",
    "                span.update(\n",
    "                    output={\"error\": str(e), \"status\": \"FAILED\"},\n",
    "                    level=\"ERROR\",\n",
    "                    status_message=f\"Quality control failed: {str(e)}\"\n",
    "                )\n",
    "                raise\n",
    "    else:\n",
    "        # Langfuse ì—†ì´ ì‹¤í–‰\n",
    "        final_post, report = await handle_qc_logic(request.topic, request.draft_content)\n",
    "        return QualityControlResponse(final_post=final_post, qa_report=report, status=\"COMPLETED\")\n",
    "\n",
    "print(\"a2a_blog_system.py íŒŒì¼ì´ Langfuse v3 SDKë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cfHY3wElyar1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_inject_services_md"
   },
   "source": [
    "### 6. ê´€ì¸¡ ê°€ëŠ¥ì„± ì£¼ì… (Part 2): ì „ë¬¸ê°€ ì„œë¹„ìŠ¤ ë‚´ë¶€ ì¶”ì \n",
    "\n",
    "Part 1ì—ì„œ ìš°ë¦¬ëŠ” ì‹œìŠ¤í…œì˜ 'ì™¸ë¶€ ê³¨ê²©'ì— í•´ë‹¹í•˜ëŠ” ì¸í”„ë¼ ê³„ì¸µ(ì„œë²„)ì— ì¶”ì  ê¸°ëŠ¥ì„ ì‹¬ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì‹œìŠ¤í…œ ë‚´ë¶€ì— í•´ë‹¹í•˜ëŠ” ê° ì „ë¬¸ê°€ ì„œë¹„ìŠ¤ ëª¨ë“ˆì˜ ë™ì‘ì„ ì¶”ì í•˜ì—¬, ë¶„ì„ì˜ ê¹Šì´ë¥¼ ë†’ì…ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” \"CrewAI íŒ€ ë‚´ë¶€ì—ì„œ ì–´ë–¤ Agentê°€ ì–´ë–¤ Toolì„ ì¼ëŠ”ê°€?\" ì™€ ê°™ì€ ì„¸ë°€í•œ ì§ˆë¬¸ì— ë‹µí•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "e2e_update_langgraph_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dialogue_manager_langgraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dialogue_manager_langgraph.py\n",
    "\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langfuse.langchain import CallbackHandler\n",
    "from langfuse import observe\n",
    "\n",
    "async def handle_dialogue_logic(user_input: str):\n",
    "    \"\"\"LangGraph Agentì˜ ì—­í• ì„ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” ëŒ€í™” ê´€ë¦¬ ë¡œì§ (Langfuse ì¶”ì  ê¸°ëŠ¥ ì¶”ê°€)\"\"\"\n",
    "    print(\"[LangGraph Service] ğŸ§  ëŒ€í™” ê´€ë¦¬ì ì‹¤í–‰ë¨...\")\n",
    "\n",
    "    # ê° ì„œë¹„ìŠ¤ í˜¸ì¶œì„ ìœ„í•œ ê³ ìœ í•œ Langfuse í•¸ë“¤ëŸ¬ ìƒì„±\n",
    "    handler = CallbackHandler()\n",
    "\n",
    "    try:\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0)\n",
    "        prompt = f\"ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ ì£¼ì œë¥¼ 20ë‹¨ì–´ ì´ë‚´ì˜ ê°„ê²°í•œ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ì‚¬ìš©ìì˜ ìˆ¨ê²¨ì§„ ìš”êµ¬ì‚¬í•­(ìŠ¤íƒ€ì¼, í†¤ì•¤ë§¤ë„ˆ ë“±)ì„ ì¶”ë¡ í•´ì¤˜. ê²°ê³¼ëŠ” 'ì£¼ì œ: [ìš”ì•½ëœ ì£¼ì œ]\\nìš”êµ¬ì‚¬í•­: [ì¶”ë¡ ëœ ìš”êµ¬ì‚¬í•­]' í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´ì¤˜. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆ.\\n\\nì‚¬ìš©ì ìš”ì²­: '{user_input}'\"\n",
    "\n",
    "        # LLM í˜¸ì¶œ ì‹œ configì— ì½œë°± í•¸ë“¤ëŸ¬ ì „ë‹¬\n",
    "        response_text = llm.invoke(prompt, config={\"callbacks\": [handler]}).content\n",
    "\n",
    "        topic = response_text.split(\"ì£¼ì œ:\")[1].split(\"ìš”êµ¬ì‚¬í•­:\")[0].strip()\n",
    "        preferences = response_text.split(\"ìš”êµ¬ì‚¬í•­:\")[1].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[LangGraph Service] ğŸ”´ LLM í˜¸ì¶œ ì˜¤ë¥˜, Fallback ë¡œì§ ì‚¬ìš©: {e}\")\n",
    "        topic = user_input\n",
    "        preferences = \"ì „ë¬¸ì ì´ë©´ì„œë„ ì‰¬ìš´ ì–´ì¡°ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\"\n",
    "\n",
    "    response = {\n",
    "        \"agent_response\": f\"ì•Œê² ìŠµë‹ˆë‹¤. '{topic}'ì— ëŒ€í•œ ë¸”ë¡œê·¸ ê¸€ ìƒì„±ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. '{preferences}' ìš”êµ¬ì‚¬í•­ì„ ë°˜ì˜í•˜ê² ìŠµë‹ˆë‹¤.\",\n",
    "        \"next_action\": {\"action\": \"CREATE_CONTENT\", \"topic\": topic, \"user_preferences\": preferences}\n",
    "    }\n",
    "    print(f\"[LangGraph Service] âœ… ë‹¤ìŒ í–‰ë™ ê²°ì •: {response['next_action']}\")\n",
    "    return response\n",
    "\n",
    "print(\"âœ… dialogue_manager_langgraph.py íŒŒì¼ì´ Langfuse ì¶”ì  ê¸°ëŠ¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "e2e_update_crewai_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting content_creation_crew.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile content_creation_crew.py\n",
    "\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.tools import BaseTool\n",
    "import json\n",
    "from mcp_client import MCPClient\n",
    "from langfuse.langchain import CallbackHandler as LangfuseCallbackHandler\n",
    "from langfuse import observe\n",
    "\n",
    "class MCPTool(BaseTool):\n",
    "    name: str\n",
    "    description: str\n",
    "    client: MCPClient\n",
    "\n",
    "    @observe(name=\"mcp-tool-call\")\n",
    "    def _run(self, query: str) -> str:\n",
    "        print(f\"  [MCP Bridge] CrewAI -> MCP Server: Calling tool '{self.name}' with query '{query}'\")\n",
    "        response = self.client.call_tool(self.name, query)\n",
    "        return json.dumps(response, ensure_ascii=False)\n",
    "\n",
    "def handle_creation_logic(topic: str, user_preferences: str, mcp_client: MCPClient):\n",
    "    print(f\"[CrewAI Service] ğŸ‘¥ ì½˜í…ì¸  ì œì‘íŒ€ ê°€ë™ë¨ (ì£¼ì œ: {topic[:30]}...)\")\n",
    "    try:\n",
    "        handler = LangfuseCallbackHandler()\n",
    "\n",
    "        crew_web_search = MCPTool(name=\"web_search\", description=\"ì›¹ì—ì„œ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.\", client=mcp_client)\n",
    "        crew_arxiv_search = MCPTool(name=\"arxiv_search\", description=\"í•™ìˆ  ë…¼ë¬¸ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.\", client=mcp_client)\n",
    "\n",
    "        llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", callbacks=[handler])\n",
    "        researcher = Agent(role=\"ì„ ì„ ë¦¬ì„œì²˜\", goal=f\"{topic}ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„\", backstory=\"ë‹¹ì‹ ì€ 20ë…„ ê²½ë ¥ì˜ ê¸°ìˆ  ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\", tools=[crew_web_search, crew_arxiv_search], llm=llm, verbose=True)\n",
    "        writer = Agent(role=\"ì „ë¬¸ ì‘ê°€\", goal=\"ë¦¬ì„œì¹˜ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ë¸”ë¡œê·¸ ê¸€ ì‘ì„±\", backstory=\"ë‹¹ì‹ ì€ ê¸°ìˆ  ë¶„ì•¼ì˜ ë² ìŠ¤íŠ¸ì…€ëŸ¬ ì‘ê°€ì…ë‹ˆë‹¤.\", llm=llm, verbose=True)\n",
    "\n",
    "        research_task = Task(description=f\"'{topic}'ì— ëŒ€í•´ ì›¹ê³¼ í•™ìˆ  ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ì‹¬ì¸µ ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.\", expected_output=\"êµ¬ì¡°í™”ëœ ë¶„ì„ ë³´ê³ ì„œ\", agent=researcher)\n",
    "        write_task = Task(description=f\"ë¦¬ì„œì¹˜ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ, '{user_preferences}' ìŠ¤íƒ€ì¼ì„ ë°˜ì˜í•˜ì—¬ ë¸”ë¡œê·¸ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.\", expected_output=\"ì™„ì„±ëœ ë¸”ë¡œê·¸ ì´ˆì•ˆ\", agent=writer, context=[research_task])\n",
    "\n",
    "        crew = Crew(\n",
    "            agents=[researcher, writer],\n",
    "            tasks=[research_task, write_task],\n",
    "            process=Process.sequential\n",
    "        )\n",
    "        result = crew.kickoff()\n",
    "        print(\"[CrewAI Service] âœ… ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ.\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        error_message = f\"CrewAI ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "        print(f\"[CrewAI Service] ğŸ”´ {error_message}\")\n",
    "        return error_message\n",
    "\n",
    "print(\"âœ… content_creation_crew.py íŒŒì¼ì´ Langfuse ì¶”ì  ê¸°ëŠ¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "e2e_update_adk_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting quality_control_adk.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile quality_control_adk.py\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "async def handle_qc_logic(topic: str, draft_content: str):\n",
    "    print(f\"[ADK Service] ğŸ§ í’ˆì§ˆ ê´€ë¦¬íŒ€ ê°€ë™ë¨ (ì£¼ì œ: {topic[:30]}...)\")\n",
    "\n",
    "    # ADK ì„œë¹„ìŠ¤ í˜¸ì¶œì„ ìœ„í•œ í•¸ë“¤ëŸ¬ ìƒì„±\n",
    "    handler = CallbackHandler()\n",
    "\n",
    "    try:\n",
    "        qa_llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n",
    "        prompt = f\"ë‹¹ì‹ ì€ ì‚¼ì„±ì „ì ê¸°ìˆ  ë¸”ë¡œê·¸ì˜ ìˆ˜ì„ í¸ì§‘ìì…ë‹ˆë‹¤. ë‹¤ìŒ ì´ˆì•ˆì„ ê²€í† í•˜ê³ , ìš°ë¦¬ ë¸”ë¡œê·¸ì˜ í†¤ì•¤ë§¤ë„ˆ(ì „ë¬¸ì , ì‹ ë¢°ê°, ëª…í™•í•¨)ì— ë§ì¶° ìµœì¢… ë°œí–‰ ê°€ëŠ¥í•œ ì™„ë²½í•œ ìµœì¢…ë³¸ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ì„¸ìš”.\\n\\nì£¼ì œ: {topic}\\nì´ˆì•ˆ: {draft_content}\"\n",
    "\n",
    "        # LLM í˜¸ì¶œ ì‹œ configì— ì½œë°± í•¸ë“¤ëŸ¬ ì „ë‹¬\n",
    "        final_post = qa_llm.invoke(prompt, config={\"callbacks\": [handler]}).content\n",
    "\n",
    "        report = {\"seo_score\": 95, \"readability\": \"excellent\", \"final_char_count\": len(final_post), \"status\": \"Approved\"}\n",
    "        print(\"[ADK Service] âœ… ìµœì¢… í¸ì§‘ ë° ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ.\")\n",
    "        return final_post, report\n",
    "    except Exception as e:\n",
    "        error_message = f\"ADK í’ˆì§ˆ ê´€ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\"\n",
    "        print(f\"[ADK Service] ğŸ”´ {error_message}\")\n",
    "        return draft_content, {\"status\": \"Failed\", \"error\": error_message}\n",
    "\n",
    "print(\"âœ… quality_control_adk.py íŒŒì¼ì´ Langfuse ì¶”ì  ê¸°ëŠ¥ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2e_final_run_md"
   },
   "source": [
    "### 8. ìµœì¢… ì‹¤í–‰ ë° í†µí•© Trace ë¶„ì„\n",
    "\n",
    "ì´ì œ ëª¨ë“  ì¤€ë¹„ê°€ ëë‚¬ìŠµë‹ˆë‹¤. ì¸í”„ë¼ ê³„ì¸µë¶€í„° ê° ì „ë¬¸ê°€ ì„œë¹„ìŠ¤ì˜ ë‚´ë¶€ê¹Œì§€, ì‹œìŠ¤í…œì˜ ëª¨ë“  ë‹¨ê³„ì— `Langfuse`ë¥¼ ì„¤ì¹˜í–ˆìŠµë‹ˆë‹¤. ì´ì œ ë‘ ê°œì˜ ì„œë²„(MCP, A2A)ë¥¼ ëª¨ë‘ ì¬ì‹¤í–‰í•˜ê³ , ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° í´ë¼ì´ì–¸íŠ¸ë¥¼ í†µí•´ ë¸”ë¡œê·¸ ìƒì„± ìš”ì²­ì„ í•œ ë²ˆ ë³´ëƒ…ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ë¦¬ê³  `Langfuse` ëŒ€ì‹œë³´ë“œì—ì„œ, ì´ ìš”ì²­ì´ ì–´ë–»ê²Œ ìˆ˜ì‹­ ê°œì˜ ê³„ì¸µì  Traceì™€ Spanìœ¼ë¡œ ê¸°ë¡ë˜ì—ˆëŠ”ì§€ í•¨ê»˜ ë¶„ì„í•´ ë³´ê² ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "e2e_final_run_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'server_launcher.py' íŒŒì¼ì´ [ë¡œì»¬ ì „ìš©]ìœ¼ë¡œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--- ğŸš€ 1. MCP ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\n",
      "ğŸš€ mcp_server ì„œë²„ë¥¼ ë¡œì»¬ í¬íŠ¸ 8501ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "   ğŸ§¹ í¬íŠ¸ 8501ì˜ ê¸°ì¡´ Uvicorn í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
      "   â³ FastAPI ì„œë²„ë¥¼ í¬íŠ¸ 8501ì—ì„œ ì‹œì‘í•˜ëŠ” ì¤‘...\n",
      "   ğŸ”Š ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[mcp_server LOG] INFO:     Will watch for changes in these directories: ['/home/elicer']\n",
      "[mcp_server LOG] INFO:     Uvicorn running on http://0.0.0.0:8501 (Press CTRL+C to quit)\n",
      "[mcp_server LOG] INFO:     Started reloader process [8648] using WatchFiles\n",
      "âœ… mcp_server ì„œë²„ê°€ ë¡œì»¬(http://localhost:8501)ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "--- ğŸš€ 2. A2A Gateway ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\n",
      "ğŸš€ a2a_blog_system ì„œë²„ë¥¼ ë¡œì»¬ í¬íŠ¸ 8502ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "   ğŸ§¹ í¬íŠ¸ 8502ì˜ ê¸°ì¡´ Uvicorn í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
      "[mcp_server LOG] INFO:     Started server process [8657]\n",
      "[mcp_server LOG] INFO:     Waiting for application startup.\n",
      "[mcp_server LOG] INFO:     Application startup complete.\n",
      "   â³ FastAPI ì„œë²„ë¥¼ í¬íŠ¸ 8502ì—ì„œ ì‹œì‘í•˜ëŠ” ì¤‘...\n",
      "   ğŸ”Š ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[a2a_blog_system LOG] INFO:     Will watch for changes in these directories: ['/home/elicer']\n",
      "[a2a_blog_system LOG] INFO:     Uvicorn running on http://0.0.0.0:8502 (Press CTRL+C to quit)\n",
      "[a2a_blog_system LOG] INFO:     Started reloader process [8677] using WatchFiles\n",
      "âœ… a2a_blog_system ì„œë²„ê°€ ë¡œì»¬(http://localhost:8502)ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "--------------------------------------------------\n",
      "--- ğŸš€ 3. ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\n",
      "ğŸš€ reverse_proxy ì„œë²„ë¥¼ ë¡œì»¬ í¬íŠ¸ 8000ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "   ğŸ§¹ í¬íŠ¸ 8000ì˜ ê¸°ì¡´ Uvicorn í”„ë¡œì„¸ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.\n",
      "   â³ FastAPI ì„œë²„ë¥¼ í¬íŠ¸ 8000ì—ì„œ ì‹œì‘í•˜ëŠ” ì¤‘...\n",
      "   ğŸ”Š ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n",
      "[reverse_proxy LOG] INFO:     Will watch for changes in these directories: ['/home/elicer']\n",
      "[reverse_proxy LOG] INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "[reverse_proxy LOG] INFO:     Started reloader process [8702] using WatchFiles\n",
      "[reverse_proxy LOG] INFO:     Started server process [8708]\n",
      "[reverse_proxy LOG] INFO:     Waiting for application startup.\n",
      "[reverse_proxy LOG] INFO:     Application startup complete.\n",
      "âœ… reverse_proxy ì„œë²„ê°€ ë¡œì»¬(http://localhost:8000)ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "============================================================\n",
      "ğŸ‰ ëª¨ë“  ì„œë²„ê°€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "   - ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ Entrypoint: http://localhost:8000\n",
      "   - MCP ì„œë²„ Local URL: http://localhost:8000/mcp\n",
      "   - A2A Gateway Local URL: http://localhost:8000/a2a\n",
      "============================================================\n",
      "\n",
      "   A2A Gateway ë° MCP ì„œë²„ ì´ˆê¸°í™” ëŒ€ê¸° ì¤‘...\n",
      "[a2a_blog_system LOG] INFO:     Started server process [8680]\n",
      "[a2a_blog_system LOG] INFO:     Waiting for application startup.\n",
      "[a2a_blog_system LOG] INFO:     Application startup complete.\n",
      "   âœ… A2A Gateway (via Proxy) ì¤€ë¹„ ì™„ë£Œ!\n",
      "\n",
      "--- ğŸš€ ìµœì¢… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ---\n",
      "\n",
      "1ï¸âƒ£  LangGraph ëŒ€í™” ê´€ë¦¬ì í˜¸ì¶œ...\n",
      "   ì‘ë‹µ ìˆ˜ì‹ : CREATE_CONTENT\n",
      "\n",
      "2ï¸âƒ£  CrewAI ì½˜í…ì¸  ì œì‘íŒ€ í˜¸ì¶œ...\n",
      "\n",
      "3ï¸âƒ£  ADK í’ˆì§ˆ ê´€ë¦¬íŒ€ í˜¸ì¶œ...\n",
      "\n",
      "================================================================================\n",
      "                           âœ… ìµœì¢… ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ âœ…\n",
      "================================================================================\n",
      "## ì‚¼ì„±ì „ì ê¸°ìˆ  ë¸”ë¡œê·¸: ë©€í‹°ëª¨ë‹¬ LLM ìµœì‹  ë™í–¥ ë° ì‚°ì—… ì ìš© ì‚¬ë¡€ ì‹¬ì¸µ ë¶„ì„\n",
      "\n",
      "---\n",
      "\n",
      "### **ì œëª©: ë©€í‹°ëª¨ë‹¬ LLM: ì¸ê°„ì²˜ëŸ¼ ì„¸ìƒì„ ì´í•´í•˜ëŠ” AIì˜ ì§„í™”ì™€ ì‚°ì—… í˜ì‹ **\n",
      "\n",
      "**ë¶€ì œ: í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ê¹Œì§€, AIê°€ ì—´ì–´ê°ˆ ìƒˆë¡œìš´ ê°€ëŠ¥ì„±**\n",
      "\n",
      "---\n",
      "\n",
      "**[ì„œë¡ ]**\n",
      "\n",
      "ì¸ê³µì§€ëŠ¥(AI)ì€ ì´ë¯¸ ìš°ë¦¬ ì‚¶ì˜ ë§ì€ ë¶€ë¶„ì„ ë³€í™”ì‹œì¼°ì§€ë§Œ, ì§„ì •í•œ ì§€ëŠ¥ì€ ë‹¨ìˆœíˆ í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ì„ ë‹¤. ì¸ê°„ì€ ì‹œê°, ì²­ê°, ì´‰ê° ë“± ë‹¤ì–‘í•œ ê°ê°ì„ í†µí•´ ì„¸ìƒì„ ì¸ì§€í•˜ê³  ì´í•´í•˜ë©° ì†Œí†µí•©ë‹ˆë‹¤. ì´ëŸ¬í•œ ì¸ê°„ì˜ ì¸ì§€ ë°©ì‹ì— í•œ ê±¸ìŒ ë” ë‹¤ê°€ì„  ê¸°ìˆ ì´ ë°”ë¡œ **ë©€í‹°ëª¨ë‹¬ ê±°ëŒ€ ì–¸ì–´ ëª¨ë¸(Multimodal Large Language Model, ì´í•˜ ë©€í‹°ëª¨ë‹¬ LLM)**ì…ë‹ˆë‹¤.\n",
      "\n",
      "ê¸°ì¡´ LLMì´ í…ìŠ¤íŠ¸ ë°ì´í„°ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì¶”ë¡ í–ˆë‹¤ë©´, ë©€í‹°ëª¨ë‹¬ LLMì€ í…ìŠ¤íŠ¸ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ë°ì´í„°ë¥¼ ë™ì‹œì— ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì„ ê°–ì¶¥ë‹ˆë‹¤. ì´ëŠ” AIê°€ ë”ìš± ë³µì¡í•˜ê³  í˜„ì‹¤ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³ , ì¸ê°„ê³¼ ë”ìš± ìì—°ìŠ¤ëŸ½ê²Œ ìƒí˜¸ì‘ìš©í•  ìˆ˜ ìˆëŠ” ìƒˆë¡œìš´ ì§€í‰ì„ ì—´ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì‚¼ì„±ì „ì ê¸°ìˆ  ë¸”ë¡œê·¸ì—ì„œëŠ” ë©€í‹°ëª¨ë‹¬ LLMì˜ ìµœì‹  ë™í–¥ì„ ì‹¬ì¸µ ë¶„ì„í•˜ê³ , ì´ í˜ì‹ ì ì¸ ê¸°ìˆ ì´ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼, íŠ¹íˆ ì‚¼ì„±ì „ìì˜ í•µì‹¬ ì‚¬ì—… ì˜ì—­ì—ì„œ ì–´ë–»ê²Œ ì ìš©ë˜ê³  ë¯¸ë˜ë¥¼ ë³€í™”ì‹œí‚¬ì§€ ì¡°ëª…í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "**[ë³¸ë¡  1: ë©€í‹°ëª¨ë‹¬ LLMì´ë€ ë¬´ì—‡ì¸ê°€?]**\n",
      "\n",
      "ë©€í‹°ëª¨ë‹¬ LLMì€ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ ë“± ì—¬ëŸ¬ ì–‘ì‹(modality)ì˜ ë°ì´í„°ë¥¼ í†µí•©ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” AI ëª¨ë¸ì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœíˆ ì´ë¯¸ì§€ë¥¼ ì„¤ëª…í•˜ëŠ” ê²ƒì„ ë„˜ì–´, ì´ë¯¸ì§€ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜, í…ìŠ¤íŠ¸ ì§€ì‹œë¥¼ ë°›ì•„ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê³ , ìŒì„± ëª…ë ¹ì„ ì´í•´í•˜ì—¬ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ë“± ë³µí•©ì ì¸ ì¸ì§€ ëŠ¥ë ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "\n",
      "ì´ëŸ¬í•œ ëª¨ë¸ì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ë°©ì‹ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.\n",
      "\n",
      "1.  **ëª¨ë‹¬ë¦¬í‹°ë³„ ì¸ì½”ë”©:** ê°ê¸° ë‹¤ë¥¸ í˜•íƒœì˜ ë°ì´í„°ë¥¼ AI ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆëŠ” ê³µí†µëœ ë²¡í„° ê³µê°„(embedding space)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì´ë¯¸ì§€ëŠ” ì‹œê° ì¸ì½”ë”ë¥¼ í†µí•´, í…ìŠ¤íŠ¸ëŠ” í…ìŠ¤íŠ¸ ì¸ì½”ë”ë¥¼ í†µí•´ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
      "2.  **ì •ë³´ ìœµí•©:** ë³€í™˜ëœ ì—¬ëŸ¬ ëª¨ë‹¬ë¦¬í‹°ì˜ ì •ë³´ë¥¼ í†µí•©í•˜ì—¬ ìƒí˜¸ ê´€ê³„ë¥¼ í•™ìŠµí•˜ê³ , ë³µí•©ì ì¸ ì˜ë¯¸ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ íŠ¸ëœìŠ¤í¬ë¨¸(Transformer) ê¸°ë°˜ì˜ ì–´í…ì…˜(Attention) ë©”ì»¤ë‹ˆì¦˜ì´ í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "3.  **ë©€í‹°ëª¨ë‹¬ ì¶”ë¡  ë° ìƒì„±:** í†µí•©ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µí•˜ê±°ë‚˜, ìƒˆë¡œìš´ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ë“± ë‹¤ì–‘í•œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "**[ë³¸ë¡  2: ë©€í‹°ëª¨ë‹¬ LLMì˜ ìµœì‹  ê¸°ìˆ  ë™í–¥]**\n",
      "\n",
      "ë©€í‹°ëª¨ë‹¬ LLM ë¶„ì•¼ëŠ” ìµœê·¼ ëª‡ ë…„ê°„ ëˆˆë¶€ì‹  ë°œì „ì„ ê±°ë“­í•˜ë©° ë‹¤ì–‘í•œ í˜ì‹ ì„ ì„ ë³´ì´ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ìš” ë™í–¥ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
      "\n",
      "1.  **í†µí•© ì•„í‚¤í…ì²˜ì˜ ì§„í™”:**\n",
      "    *   **ë‹¨ì¼ ëª¨ë¸ í†µí•©:** í…ìŠ¤íŠ¸, ì´ë¯¸ì§€, ìŒì„± ë“± ëª¨ë“  ëª¨ë‹¬ë¦¬í‹°ë¥¼ í•˜ë‚˜ì˜ ê±°ëŒ€í•œ íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ë¡œ ì²˜ë¦¬í•˜ë ¤ëŠ” ì‹œë„ê°€ í™œë°œí•©ë‹ˆë‹¤. ì´ëŠ” ëª¨ë¸ì˜ ë²”ìš©ì„±ê³¼ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ë° ê¸°ì—¬í•©ë‹ˆë‹¤. Googleì˜ Gemini, OpenAIì˜ GPT-4V ë“±ì´ ëŒ€í‘œì ì¸ ì˜ˆì‹œì…ë‹ˆë‹¤.\n",
      "    *   **íš¨ìœ¨ì ì¸ ìœµí•© ì „ëµ:** ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹° ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê²°í•©í•˜ê¸° ìœ„í•œ í¬ë¡œìŠ¤-ì–´í…ì…˜(Cross-Attention), ì–´ëŒ‘í„°(Adapter) ê¸°ë°˜ ìœµí•© ë“± ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ì—°êµ¬ê°€ ì§„í–‰ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "2.  **ë°ì´í„°ì…‹ì˜ ëŒ€ê·œëª¨í™” ë° ë‹¤ì–‘í™”:**\n",
      "    *   ë©€í‹°ëª¨ë‹¬ LLMì˜ ì„±ëŠ¥ í–¥ìƒì—ëŠ” ëŒ€ê·œëª¨ì˜ ê³ í’ˆì§ˆ ë©€í‹°ëª¨ë‹¬ ë°ì´í„°ì…‹ êµ¬ì¶•ì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤. ì›¹ ìŠ¤ì¼€ì¼ì˜ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ, ë¹„ë””ì˜¤-í…ìŠ¤íŠ¸ ìŒ, ìŒì„±-í…ìŠ¤íŠ¸ ìŒ ë°ì´í„°ì…‹ì´ ì§€ì†ì ìœ¼ë¡œ í™•ì¥ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ë‹¨ìˆœí•œ ë°ì´í„° ì–‘ì„ ë„˜ì–´, ë°ì´í„°ì˜ ë‹¤ì–‘ì„±ê³¼ ë³µì¡ì„±ì„ ë†’ì—¬ ëª¨ë¸ì´ ë”ìš± í’ë¶€í•œ ë§¥ë½ì„ ì´í•´í•˜ë„ë¡ ë•ëŠ” ì—°êµ¬ë„ í™œë°œí•©ë‹ˆë‹¤.\n",
      "\n",
      "3.  **ìƒˆë¡œìš´ ëŠ¥ë ¥ì˜ ë°œí˜„:**\n",
      "    *   **ì‹œê° ì§ˆì˜ì‘ë‹µ(Visual Question Answering, VQA):** ì´ë¯¸ì§€ ë‚´ìš©ì„ ì´í•´í•˜ê³  ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•˜ëŠ” ëŠ¥ë ¥.\n",
      "    *   **í…ìŠ¤íŠ¸-ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ìƒì„±:** í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë§Œìœ¼ë¡œ ê³ í’ˆì§ˆì˜ ì´ë¯¸ì§€ë‚˜ ë¹„ë””ì˜¤ë¥¼ ìƒì„±í•˜ëŠ” ê¸°ìˆ (ì˜ˆ: DALL-E, Midjourney, Sora).\n",
      "    *   **ìŒì„± ì¸ì‹ ë° í•©ì„±:** ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ì¸ì‹ê³¼ ì‚¬ëŒê³¼ ìœ ì‚¬í•œ ìŒì„± í•©ì„± ê¸°ìˆ .\n",
      "    *   **ì„ë² ë””ë“œ AI (Embodied AI):** ë¡œë´‡ì´ë‚˜ ììœ¨ì£¼í–‰ì°¨ì™€ ê°™ì€ ë¬¼ë¦¬ì  í™˜ê²½ì—ì„œ ë©€í‹°ëª¨ë‹¬ ì •ë³´ë¥¼ í™œìš©í•˜ì—¬ ì¸ì§€, íŒë‹¨, í–‰ë™í•˜ëŠ” ëŠ¥ë ¥.\n",
      "\n",
      "4.  **ì˜¨ë””ë°”ì´ìŠ¤(On-Device) AIë¡œì˜ í™•ì¥:**\n",
      "    *   í´ë¼ìš°ë“œ ê¸°ë°˜ì˜ ëŒ€ê·œëª¨ ëª¨ë¸ì„ ë„˜ì–´, ìŠ¤ë§ˆíŠ¸í°, ê°€ì „ì œí’ˆ ë“± ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œë„ ë©€í‹°ëª¨ë‹¬ LLMì„ íš¨ìœ¨ì ìœ¼ë¡œ êµ¬ë™í•˜ê¸° ìœ„í•œ ê²½ëŸ‰í™”, ìµœì í™” ê¸°ìˆ ì´ ì¤‘ìš”í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì‚¬ìš©ì ê²½í—˜ í–¥ìƒê³¼ ê°œì¸ ì •ë³´ ë³´í˜¸ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "**[ë³¸ë¡  3: ë©€í‹°ëª¨ë‹¬ LLMì˜ ì‚°ì—… ì ìš© ì‚¬ë¡€ ë° ì‚¼ì„±ì „ìì˜ ë¹„ì „]**\n",
      "\n",
      "ë©€í‹°ëª¨ë‹¬ LLMì€ ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì—ì„œ í˜ì‹ ì ì¸ ë³€í™”ë¥¼ ì´ëŒ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, ì‚¼ì„±ì „ìëŠ” ì´ ê¸°ìˆ ì„ í†µí•´ ë¯¸ë˜ë¥¼ ì„ ë„í•˜ê³ ì í•©ë‹ˆë‹¤.\n",
      "\n",
      "1.  **ì†Œë¹„ì ê°€ì „ ë° ëª¨ë°”ì¼ ê²½í—˜ í˜ì‹ :**\n",
      "    *   **ìŠ¤ë§ˆíŠ¸í°:** ì¹´ë©”ë¼ ì•±ì—ì„œ ì´¬ì˜ëœ ì´ë¯¸ì§€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ì´¬ì˜ ì„¤ì •ì„ ì œì•ˆí•˜ê±°ë‚˜, ê°¤ëŸ¬ë¦¬ ë‚´ ì´ë¯¸ì§€ì— ëŒ€í•œ ë³µí•©ì ì¸ ì§ˆë¬¸ì— ë‹µë³€(ì˜ˆ: \"ì´ ì‚¬ì§„ ì† ê°•ì•„ì§€ê°€ ì–´ë–¤ í’ˆì¢…ì¸ì§€ ì•Œë ¤ì¤˜\"). ì˜¨ë””ë°”ì´ìŠ¤ AIë¥¼ í†µí•´ ê°œì¸í™”ëœ ë¹„ì„œ ê¸°ëŠ¥(Bixby)ì„ ë”ìš± ê³ ë„í™”í•˜ì—¬ ìŒì„±, í…ìŠ¤íŠ¸, ì‹œê° ì •ë³´ë¥¼ í†µí•©ì ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
      "    *   **ìŠ¤ë§ˆíŠ¸ TV:** ì‹œì²­ ì¤‘ì¸ ì½˜í…ì¸ ì˜ ì¥ë©´ì„ ë¶„ì„í•˜ì—¬ ê´€ë ¨ ì •ë³´ë¥¼ ì œê³µí•˜ê±°ë‚˜, ìŒì„± ëª…ë ¹ê³¼ ì œìŠ¤ì²˜ë¥¼ ë™ì‹œì— ì¸ì‹í•˜ì—¬ ë”ìš± ì§ê´€ì ì¸ ì œì–´ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤. ê°œì¸ì˜ ì‹œì²­ ì´ë ¥ê³¼ ì„ í˜¸ë„ë¥¼ ë©€í‹°ëª¨ë‹¬ë¡œ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì½˜í…ì¸ ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
      "    *   **ìŠ¤ë§ˆíŠ¸ í™ˆ ë° ê°€ì „ì œí’ˆ:** ëƒ‰ì¥ê³  ë‚´ë¶€ì˜ ì‹ì¬ë£Œ ì´ë¯¸ì§€ë¥¼ ì¸ì‹í•˜ì—¬ ë ˆì‹œí”¼ë¥¼ ì¶”ì²œí•˜ê³ , ì„¸íƒê¸°ë‚˜ ì—ì–´ì»¨ì˜ ì´ìƒ ì§•í›„(ì†Œë¦¬, ì§„ë™)ë¥¼ ê°ì§€í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ì•Œë¦¬ëŠ” ë“± ë”ìš± ì§€ëŠ¥ì ì¸ ìŠ¤ë§ˆíŠ¸ í™ˆ í™˜ê²½ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
      "\n",
      "2.  **ë°˜ë„ì²´ ë° ë¶€í’ˆ ì†”ë£¨ì…˜:**\n",
      "    *   **AI ì¹© ì„¤ê³„:** ë©€í‹°ëª¨ë‹¬ LLMì˜ ë³µì¡í•œ ì—°ì‚°ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì°¨ì„¸ëŒ€ NPU(Neural Processing Unit) ë° ì €ì „ë ¥ ê³ ì„±ëŠ¥ AI ë°˜ë„ì²´ ê°œë°œì— ì§‘ì¤‘í•©ë‹ˆë‹¤.\n",
      "    *   **ë©”ëª¨ë¦¬ ì†”ë£¨ì…˜:** ëŒ€ê·œëª¨ ë©€í‹°ëª¨ë‹¬ ëª¨ë¸ì˜ í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¹ ë¥´ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ê³ ëŒ€ì—­í­ ë©”ëª¨ë¦¬(HBM), í”„ë¡œì„¸ì‹±-ì¸-ë©”ëª¨ë¦¬(PIM) ë“± í˜ì‹ ì ì¸ ë©”ëª¨ë¦¬ ì†”ë£¨ì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.\n",
      "    *   **ì—£ì§€ AI:** ìŠ¤ë§ˆíŠ¸í°, ì›¨ì–´ëŸ¬ë¸”, IoT ê¸°ê¸° ë“± ì—£ì§€ ë””ë°”ì´ìŠ¤ì—ì„œ ë©€í‹°ëª¨ë‹¬ AIë¥¼ êµ¬ë™í•˜ê¸° ìœ„í•œ ìµœì í™”ëœ ë°˜ë„ì²´ ì†”ë£¨ì…˜ì„ ê°œë°œí•˜ì—¬ ì˜¨ë””ë°”ì´ìŠ¤ AI ì‹œëŒ€ë¥¼ ì„ ë„í•©ë‹ˆë‹¤.\n",
      "\n",
      "3.  **ì‚°ì—… ë° ê¸°ì—… ì†”ë£¨ì…˜:**\n",
      "    *   **ì œì¡° ë° í’ˆì§ˆ ê´€ë¦¬:** ìƒì‚° ë¼ì¸ì—ì„œ ì œí’ˆì˜ ë¯¸ì„¸í•œ ê²°í•¨ì„ ì´ë¯¸ì§€ ë° ìŒí–¥ ë¶„ì„ì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•˜ê³ , ì´ìƒ ì§•í›„ë¥¼ ì˜ˆì¸¡í•˜ì—¬ ìƒì‚° íš¨ìœ¨ì„±ê³¼ í’ˆì§ˆì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.\n",
      "    *   **í—¬ìŠ¤ì¼€ì–´:** ì˜ë£Œ ì˜ìƒ(X-ray, MRI, CT)ê³¼ í™˜ìì˜ ì§„ë£Œ ê¸°ë¡, ìŒì„± ë°ì´í„°ë¥¼ í†µí•© ë¶„ì„í•˜ì—¬ ì§ˆë³‘ ì§„ë‹¨ì„ ë³´ì¡°í•˜ê³ , ê°œì¸ ë§ì¶¤í˜• ì¹˜ë£Œ ê³„íš ìˆ˜ë¦½ì— ê¸°ì—¬í•©ë‹ˆë‹¤.\n",
      "    *   **ë¡œë´‡ ë° ììœ¨ì£¼í–‰:** ì£¼ë³€ í™˜ê²½ì„ ì‹œê°, ìŒì„±, ë ˆì´ë” ë“± ë‹¤ì–‘í•œ ì„¼ì„œë¡œ ì¸ì§€í•˜ê³ , ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë³µì¡í•œ ìƒí™©ì„ íŒë‹¨í•˜ì—¬ ììœ¨ì ìœ¼ë¡œ í–‰ë™í•˜ëŠ” ë¡œë´‡ ë° ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ ê°œë°œì— í•µì‹¬ì ì¸ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "**[ê²°ë¡ ]**\n",
      "\n",
      "ë©€í‹°ëª¨ë‹¬ LLMì€ AIê°€ ì¸ê°„ì˜ ì¸ì§€ ë°©ì‹ì— ë”ìš± ê°€ê¹Œì›Œì§€ë©°, í˜„ì‹¤ ì„¸ê³„ì˜ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° í•„ìˆ˜ì ì¸ ê¸°ìˆ ë¡œ ìë¦¬ë§¤ê¹€í•˜ê³  ìˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ë¥¼ ë„˜ì–´ ì´ë¯¸ì§€, ìŒì„±, ë¹„ë””ì˜¤ ë“± ë‹¤ì–‘í•œ ëª¨ë‹¬ë¦¬í‹°ë¥¼ í†µí•©ì ìœ¼ë¡œ ì´í•´í•˜ê³  ìƒì„±í•˜ëŠ” ëŠ¥ë ¥ì€ AIì˜ í™œìš© ë²”ìœ„ë¥¼ ë¬´í•œíˆ í™•ì¥í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ë¬¼ë¡ , ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ êµ¬ì¶•, ëª¨ë¸ì˜ íš¨ìœ¨ì ì¸ í•™ìŠµ ë° ì¶”ë¡ , ìœ¤ë¦¬ì  ë¬¸ì œ í•´ê²° ë“± ì—¬ì „íˆ ë§ì€ ë„ì „ ê³¼ì œê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì‚¼ì„±ì „ìëŠ” ì´ëŸ¬í•œ ë„ì „ ê³¼ì œë¥¼ ê·¹ë³µí•˜ê³ , ë©€í‹°ëª¨ë‹¬ LLM ê¸°ìˆ ì„ í†µí•´ ì‚¬ìš©ìì—ê²Œ ë”ìš± í’ë¶€í•˜ê³  ì§ê´€ì ì¸ ê²½í—˜ì„ ì œê³µí•˜ë©°, ë‹¤ì–‘í•œ ì‚°ì—… ë¶„ì•¼ì˜ í˜ì‹ ì„ ì´ëŒì–´ ë‚˜ê°ˆ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¼ì„±ì „ìëŠ” AI ê¸°ìˆ ì˜ ìµœì „ì„ ì—ì„œ ë©€í‹°ëª¨ë‹¬ LLM ì—°êµ¬ ê°œë°œì— ì§€ì†ì ìœ¼ë¡œ íˆ¬ìí•˜ê³  ìˆìœ¼ë©°, ì´ë¥¼ í†µí•´ ì¸ë¥˜ì˜ ì‚¶ì„ ë”ìš± í’ìš”ë¡­ê²Œ ë§Œë“œëŠ” ê¸°ìˆ  í˜ì‹ ì„ ì„ ë„í•´ ë‚˜ê°ˆ ê²ƒì„ ì•½ì†ë“œë¦½ë‹ˆë‹¤. ì•ìœ¼ë¡œë„ ì‚¼ì„±ì „ì ê¸°ìˆ  ë¸”ë¡œê·¸ë¥¼ í†µí•´ ë©€í‹°ëª¨ë‹¬ LLMì˜ ë°œì „ê³¼ ê·¸ ì ìš© ì‚¬ë¡€ì— ëŒ€í•œ ê¹Šì´ ìˆëŠ” í†µì°°ì„ ê³„ì†í•´ì„œ ê³µìœ í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "**[íƒœê·¸]**\n",
      "#ë©€í‹°ëª¨ë‹¬LLM #ì¸ê³µì§€ëŠ¥ #AI #ê±°ëŒ€ì–¸ì–´ëª¨ë¸ #MultimodalAI #ì‚¼ì„±ì „ì #ê¸°ìˆ íŠ¸ë Œë“œ #ì‚°ì—…í˜ì‹  #ì˜¨ë””ë°”ì´ìŠ¤AI #ë¹„ì „AI #ìŒì„±AI #ìƒì„±AI #AIë°˜ë„ì²´ #ìŠ¤ë§ˆíŠ¸í° #ìŠ¤ë§ˆíŠ¸TV #ê°€ì „ì œí’ˆ #ë¯¸ë˜ê¸°ìˆ \n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b><a href=\"https://cloud.langfuse.com/project/pk-lf-11135925-919c-4df5-baa1-a510de20e4c9/sessions/e2e-session-d42d363b\" target=\"_blank\">ğŸ‘‰ Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ì´ ì„¸ì…˜ì˜ ëª¨ë“  ê³¼ì •ì„ í™•ì¸í•˜ì„¸ìš”! ğŸš€</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import server_launcher\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import uuid\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- 1. ê°œë³„ ì„œë²„ë“¤ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ---\n",
    "print(\"--- ğŸš€ 1. MCP ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\")\n",
    "_, mcp_proc = server_launcher.launch_fastapi_app(\"mcp_server\", 8501)\n",
    "if not mcp_proc:\n",
    "    raise RuntimeError(\"MCP ì„œë²„ ì‹œì‘ ì‹¤íŒ¨!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "print(\"--- ğŸš€ 2. A2A Gateway ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\")\n",
    "_, a2a_proc = server_launcher.launch_fastapi_app(\"a2a_blog_system\", 8502)\n",
    "if not a2a_proc:\n",
    "    raise RuntimeError(\"A2A Gateway ì„œë²„ ì‹œì‘ ì‹¤íŒ¨!\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# --- 2. ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„œë²„(í¬íŠ¸ 8000)ë¥¼ ë¡œì»¬ì—ì„œ ì‹¤í–‰ ---\n",
    "print(\"--- ğŸš€ 3. ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„œë²„ ë¡œì»¬ ì‹¤í–‰ ì‹œì‘ ---\")\n",
    "proxy_local_url, proxy_proc = server_launcher.launch_fastapi_app(\"reverse_proxy\", 8000)\n",
    "if not proxy_local_url:\n",
    "    raise RuntimeError(\"ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ ì„œë²„ ì‹œì‘ ì‹¤íŒ¨!\")\n",
    "\n",
    "\n",
    "# --- 3. ìµœì¢… Local URL êµ¬ì„± ë° ì„œë²„ ìƒíƒœ í™•ì¸ ---\n",
    "mcp_url = f\"{proxy_local_url}/mcp\"\n",
    "a2a_url = f\"{proxy_local_url}/a2a\"\n",
    "os.environ[\"MCP_SERVER_URL\"] = \"http://localhost:8501\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ ëª¨ë“  ì„œë²„ê°€ ë¡œì»¬ í™˜ê²½ì—ì„œ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"   - ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ Entrypoint: {proxy_local_url}\")\n",
    "print(f\"   - MCP ì„œë²„ Local URL: {mcp_url}\")\n",
    "print(f\"   - A2A Gateway Local URL: {a2a_url}\")\n",
    "print(\"=\" * 60 + \"\\n\")\n",
    "\n",
    "# ì„œë²„ ìƒíƒœ í™•ì¸\n",
    "print(\"   A2A Gateway ë° MCP ì„œë²„ ì´ˆê¸°í™” ëŒ€ê¸° ì¤‘...\")\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "try:\n",
    "    # í”„ë¡ì‹œë¥¼ í†µí•´ A2A ì„œë²„ì˜ ë£¨íŠ¸ ê²½ë¡œ('/')ì— ìš”ì²­í•˜ì—¬ ìµœì¢… ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "    test_response = requests.get(f\"{a2a_url}/\", timeout=10)\n",
    "    if test_response.status_code == 200:\n",
    "        print(\"   âœ… A2A Gateway (via Proxy) ì¤€ë¹„ ì™„ë£Œ!\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸ A2A Gateway ì‘ë‹µ ì½”ë“œ: {test_response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"   âš ï¸ A2A Gateway ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}, ê³„ì† ì§„í–‰...\")\n",
    "\n",
    "\n",
    "# --- 4. ìµœì¢… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰ (ë¡œì»¬ URL ì‚¬ìš©) ---\n",
    "if mcp_proc and a2a_proc and proxy_proc:\n",
    "    session_id = f\"e2e-session-{uuid.uuid4().hex[:8]}\"\n",
    "    user_id = \"samsung-final-user\"\n",
    "    initial_user_input = \"ë©€í‹°ëª¨ë‹¬ LLMì˜ ìµœì‹  ê¸°ìˆ  ë™í–¥ê³¼ ì‚°ì—…ë³„ ì ìš© ì‚¬ë¡€ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ë¸”ë¡œê·¸ ê¸€ì„ ì¨ì¤˜.\"\n",
    "    headers = {\n",
    "        \"X-API-Key\": os.environ[\"MASTER_API_KEY\"],\n",
    "        \"X-Session-ID\": session_id,\n",
    "        \"X-User-ID\": user_id,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "\n",
    "    print(\"\\n--- ğŸš€ ìµœì¢… ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ---\")\n",
    "    try:\n",
    "        print(\"\\n1ï¸âƒ£  LangGraph ëŒ€í™” ê´€ë¦¬ì í˜¸ì¶œ...\")\n",
    "        dialogue_req = {\"session_id\": session_id, \"user_input\": initial_user_input}\n",
    "\n",
    "        dialogue_response = requests.post(f\"{a2a_url}/api/v1/dialogue\", json=dialogue_req, headers=headers, timeout=120)\n",
    "        dialogue_response.raise_for_status()\n",
    "        dialogue_res = dialogue_response.json()\n",
    "\n",
    "        print(f\"   ì‘ë‹µ ìˆ˜ì‹ : {dialogue_res.get('next_action', {}).get('action')}\")\n",
    "\n",
    "        next_action = dialogue_res.get(\"next_action\")\n",
    "        if next_action and next_action.get(\"action\") == \"CREATE_CONTENT\":\n",
    "            print(\"\\n2ï¸âƒ£  CrewAI ì½˜í…ì¸  ì œì‘íŒ€ í˜¸ì¶œ...\")\n",
    "            # A2A Gatewayê°€ MCP ì„œë²„ì™€ í†µì‹ í•  ìˆ˜ ìˆë„ë¡ í™˜ê²½ë³€ìˆ˜ë¥¼ ì§ì ‘ ë‚´ë¶€ ì£¼ì†Œë¡œ ì„¤ì •\n",
    "            os.environ[\"MCP_SERVER_URL\"] = \"http://localhost:8501\"\n",
    "\n",
    "            creation_response = requests.post(\n",
    "                f\"{a2a_url}/api/v1/create-content\", json=next_action, headers=headers, timeout=300\n",
    "            )\n",
    "            creation_response.raise_for_status()\n",
    "            creation_res = creation_response.json()\n",
    "            draft_content = creation_res.get(\"draft_content\", \"\")\n",
    "\n",
    "            if creation_res.get(\"status\") == \"COMPLETED\" and draft_content:\n",
    "                print(\"\\n3ï¸âƒ£  ADK í’ˆì§ˆ ê´€ë¦¬íŒ€ í˜¸ì¶œ...\")\n",
    "                qc_req = {\"topic\": next_action[\"topic\"], \"draft_content\": draft_content}\n",
    "                qc_response = requests.post(\n",
    "                    f\"{a2a_url}/api/v1/quality-control\", json=qc_req, headers=headers, timeout=120\n",
    "                )\n",
    "                qc_response.raise_for_status()\n",
    "                qc_res = qc_response.json()\n",
    "                final_post = qc_res.get(\"final_post\", draft_content)\n",
    "\n",
    "                print(\"\\n\" + \"=\" * 80)\n",
    "                print(\"                           âœ… ìµœì¢… ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ âœ…\")\n",
    "                print(\"=\" * 80)\n",
    "                print(final_post)\n",
    "\n",
    "                trace_url = f\"https://cloud.langfuse.com/project/{os.environ.get('LANGFUSE_PUBLIC_KEY', 'unknown')}/sessions/{session_id}\"\n",
    "                print(\"\\n\" + \"-\" * 80)\n",
    "                display(\n",
    "                    HTML(\n",
    "                        f'<b><a href=\"{trace_url}\" target=\"_blank\">ğŸ‘‰ Langfuse ëŒ€ì‹œë³´ë“œì—ì„œ ì´ ì„¸ì…˜ì˜ ëª¨ë“  ê³¼ì •ì„ í™•ì¸í•˜ì„¸ìš”! ğŸš€</a></b>'\n",
    "                    )\n",
    "                )\n",
    "            else:\n",
    "                print(f\"\\nâŒ ì½˜í…ì¸  ìƒì„± ì‹¤íŒ¨: {creation_res}\")\n",
    "        else:\n",
    "            print(f\"\\nâŒ ëŒ€í™” ê´€ë¦¬ìì—ì„œ ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ: {dialogue_res}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ìµœì¢… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "else:\n",
    "    print(\"\\nâŒ ì„œë²„ ì‹œì‘ì— ì‹¤íŒ¨í•˜ì—¬ ìµœì¢… ì‹¤í–‰ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ws9YxoiEJsVk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰ ===\n",
      "MCP ì„œë²„ ì‘ë‹µ: 200\n",
      "A2A ì„œë²„ ì‘ë‹µ: 200\n",
      "âœ… ë‘ ì„œë²„ ëª¨ë‘ ì •ìƒ ì‘ë‹µ! ì´ì œ ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n=== ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ ë¨¼ì € ì‹¤í–‰ ===\")\n",
    "try:\n",
    "    # MCP ì„œë²„ í…ŒìŠ¤íŠ¸\n",
    "    mcp_test = requests.get(f\"{mcp_url}/\", timeout=30)\n",
    "    print(f\"MCP ì„œë²„ ì‘ë‹µ: {mcp_test.status_code}\")\n",
    "\n",
    "    # A2A ì„œë²„ í…ŒìŠ¤íŠ¸\n",
    "    a2a_test = requests.get(f\"{a2a_url}/\", timeout=30)\n",
    "    print(f\"A2A ì„œë²„ ì‘ë‹µ: {a2a_test.status_code}\")\n",
    "\n",
    "    if mcp_test.status_code == 200 and a2a_test.status_code == 200:\n",
    "        print(\"âœ… ë‘ ì„œë²„ ëª¨ë‘ ì •ìƒ ì‘ë‹µ! ì´ì œ ì „ì²´ ì‹œìŠ¤í…œì„ ì‹¤í–‰í•©ë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âŒ ì„œë²„ ì‘ë‹µ ë¬¸ì œ ìˆìŒ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ê¸°ë³¸ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Oh_CR949zH1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
