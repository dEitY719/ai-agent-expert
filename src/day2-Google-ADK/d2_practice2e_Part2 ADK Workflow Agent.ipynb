{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro_md"
   },
   "source": [
    "# [Lv4-Day2-Lab2] Part 2: ADK `Workflow Agent` - LangGraph 통합 실습\n",
    "\n",
    "### 실습 목표\n",
    "Part 1에서 확인한 `LLM Agent`의 Stateless 한계를 극복하기 위해, ADK의 **Workflow Agent**와 **LangGraph**를 통합하여 복잡한 다단계 작업을 처리하는 Agent를 구축합니다.\n",
    "\n",
    "1. **LangGraph 워크플로우 구축**: Self-Correcting 리서치 Agent를 LangGraph로 구현\n",
    "2. **ADK Workflow Agent 통합**: LangGraph를 ADK의 Tool로 통합\n",
    "3. **Stateful 동작 확인**: 이전 단계를 기억하며 연속적으로 작업 수행\n",
    "4. **비교 분석**: Stateless vs Stateful Agent의 차이점 명확히 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_md"
   },
   "source": [
    "## 🚀 1. 라이브러리 설치 및 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "install_code"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "# !pip install --upgrade --quiet google-adk\n",
    "# !pip install --upgrade --quiet langchain-google-genai\n",
    "# !pip install --upgrade --quiet langchain-community\n",
    "# !pip install --upgrade --quiet langgraph\n",
    "# !pip install --upgrade --quiet tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "api_setup_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tavily API 키를 입력하세요 (https://tavily.com 무료 발급): ········\n",
      "✅ API 키 설정이 완료되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# API 키 설정\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    api_key = \"AIzaSyDVYEpxB86k5-Oi2BApqTr47nnGJ0BwkOc\"\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    tavily_key = getpass(\"Tavily API 키를 입력하세요 (https://tavily.com 무료 발급): \")\n",
    "    os.environ[\"TAVILY_API_KEY\"] = tavily_key\n",
    "\n",
    "print(\"✅ API 키 설정이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "langgraph_md"
   },
   "source": [
    "## 🏗️ 2. LangGraph 기반 리서치 워크플로우 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "langgraph_setup_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph 기본 구성 요소가 준비되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_178/1925045884.py:21: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import json\n",
    "\n",
    "\n",
    "# 1. State 정의\n",
    "class ResearchState(TypedDict):\n",
    "    topic: str\n",
    "    sub_questions: List[str]\n",
    "    current_question: str\n",
    "    researched_data: Annotated[list, operator.add]\n",
    "    final_report: str\n",
    "    step_count: int\n",
    "\n",
    "\n",
    "# 2. Tools 및 LLM 초기화\n",
    "web_search_tool = TavilySearchResults(max_results=3)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n",
    "\n",
    "\n",
    "# 3. 구조화된 출력을 위한 모델\n",
    "class SubQuestions(BaseModel):\n",
    "    questions: List[str] = Field(description=\"3개의 핵심 세부 질문들\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(SubQuestions)\n",
    "\n",
    "print(\"✅ LangGraph 기본 구성 요소가 준비되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "langgraph_nodes_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph 노드 함수들이 정의되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# LangGraph 노드 함수들 정의\n",
    "def planning_node(state: ResearchState):\n",
    "    \"\"\"주제 분석 및 세부 질문 생성\"\"\"\n",
    "    print(f\"📋 계획 단계: '{state['topic']}' 분석 중...\")\n",
    "\n",
    "    prompt = f\"\"\"주제: {state['topic']}\n",
    "\n",
    "이 주제에 대한 포괄적인 리서치 보고서를 작성하기 위해 필요한 3개의 핵심 세부 질문을 생성해주세요.\n",
    "각 질문은 서로 다른 측면을 다루어야 하고, 웹 검색으로 답변 가능해야 합니다.\"\"\"\n",
    "\n",
    "    sub_questions_result = structured_llm.invoke(prompt)\n",
    "    questions = sub_questions_result.questions\n",
    "\n",
    "    print(f\"   ➤ 생성된 질문 수: {len(questions)}\")\n",
    "    for i, q in enumerate(questions, 1):\n",
    "        print(f\"     {i}. {q}\")\n",
    "\n",
    "    return {\"sub_questions\": questions, \"step_count\": state.get(\"step_count\", 0) + 1}\n",
    "\n",
    "\n",
    "def research_node(state: ResearchState):\n",
    "    \"\"\"웹 검색을 통한 개별 질문 조사\"\"\"\n",
    "    if not state[\"sub_questions\"]:\n",
    "        return state\n",
    "\n",
    "    current_question = state[\"sub_questions\"][0]\n",
    "    remaining_questions = state[\"sub_questions\"][1:]\n",
    "\n",
    "    print(f\"🔍 조사 단계: '{current_question}' 검색 중...\")\n",
    "\n",
    "    # 웹 검색 수행\n",
    "    search_results = web_search_tool.invoke(current_question)\n",
    "\n",
    "    # 검색 결과 정리\n",
    "    search_summary = []\n",
    "    for result in search_results:\n",
    "        if \"content\" in result and result[\"content\"]:\n",
    "            search_summary.append(result[\"content\"][:300])  # 각 결과의 첫 300자만\n",
    "\n",
    "    research_data = {\"question\": current_question, \"answer\": \" \".join(search_summary)}\n",
    "\n",
    "    print(f\"   ➤ 검색 완료 (결과 {len(search_results)}개)\")\n",
    "\n",
    "    return {\n",
    "        \"sub_questions\": remaining_questions,\n",
    "        \"current_question\": current_question,\n",
    "        \"researched_data\": [research_data],\n",
    "        \"step_count\": state.get(\"step_count\", 0) + 1,\n",
    "    }\n",
    "\n",
    "\n",
    "def synthesis_node(state: ResearchState):\n",
    "    \"\"\"조사 결과 종합 및 최종 보고서 작성\"\"\"\n",
    "    print(f\"📝 종합 단계: 최종 보고서 작성 중...\")\n",
    "\n",
    "    # 조사 결과 정리\n",
    "    research_summary = []\n",
    "    for data in state[\"researched_data\"]:\n",
    "        research_summary.append(f\"질문: {data['question']}\\n답변: {data['answer']}\")\n",
    "\n",
    "    combined_research = \"\\n\\n\".join(research_summary)\n",
    "\n",
    "    # 최종 보고서 생성\n",
    "    final_prompt = f\"\"\"주제: {state['topic']}\n",
    "\n",
    "다음은 이 주제에 대한 상세한 조사 결과입니다:\n",
    "\n",
    "{combined_research}\n",
    "\n",
    "위 조사 결과를 바탕으로 다음 구조의 체계적이고 전문적인 보고서를 작성해주세요:\n",
    "\n",
    "1. **개요** (주제의 중요성과 현황)\n",
    "2. **주요 내용** (각 조사 결과의 핵심 포인트)\n",
    "3. **분석 및 인사이트** (조사 결과들 간의 연관성과 시사점)\n",
    "4. **결론** (핵심 메시지와 향후 전망)\n",
    "\n",
    "보고서는 전문적이고 읽기 쉽게 작성해주세요.\"\"\"\n",
    "\n",
    "    final_report = llm.invoke(final_prompt)\n",
    "\n",
    "    print(f\"   ➤ 보고서 작성 완료 ({len(final_report.content)} 글자)\")\n",
    "\n",
    "    return {\"final_report\": final_report.content, \"step_count\": state.get(\"step_count\", 0) + 1}\n",
    "\n",
    "\n",
    "# 라우팅 함수\n",
    "def should_continue_research(state: ResearchState):\n",
    "    \"\"\"더 조사할 질문이 있는지 확인\"\"\"\n",
    "    if state[\"sub_questions\"]:\n",
    "        return \"continue_research\"\n",
    "    else:\n",
    "        return \"synthesize\"\n",
    "\n",
    "\n",
    "print(\"✅ LangGraph 노드 함수들이 정의되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "langgraph_graph_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LangGraph 리서치 워크플로우가 생성되었습니다.\n",
      "   📊 노드: planning → research (반복) → synthesis\n",
      "   🧠 메모리: MemorySaver로 상태 유지\n"
     ]
    }
   ],
   "source": [
    "# LangGraph 워크플로우 구성\n",
    "def create_research_graph():\n",
    "    \"\"\"리서치 워크플로우 그래프 생성\"\"\"\n",
    "\n",
    "    # StateGraph 생성\n",
    "    workflow = StateGraph(ResearchState)\n",
    "\n",
    "    # 노드 추가\n",
    "    workflow.add_node(\"planning\", planning_node)\n",
    "    workflow.add_node(\"research\", research_node)\n",
    "    workflow.add_node(\"synthesis\", synthesis_node)\n",
    "\n",
    "    # 엣지 설정\n",
    "    workflow.set_entry_point(\"planning\")\n",
    "    workflow.add_edge(\"planning\", \"research\")\n",
    "\n",
    "    # 조건부 엣지: 더 조사할 질문이 있으면 research 반복, 없으면 synthesis로\n",
    "    workflow.add_conditional_edges(\n",
    "        \"research\", should_continue_research, {\"continue_research\": \"research\", \"synthesize\": \"synthesis\"}\n",
    "    )\n",
    "\n",
    "    workflow.add_edge(\"synthesis\", END)\n",
    "\n",
    "    # 메모리와 함께 컴파일\n",
    "    return workflow.compile(checkpointer=MemorySaver())\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "research_graph = create_research_graph()\n",
    "\n",
    "print(\"✅ LangGraph 리서치 워크플로우가 생성되었습니다.\")\n",
    "print(\"   📊 노드: planning → research (반복) → synthesis\")\n",
    "print(\"   🧠 메모리: MemorySaver로 상태 유지\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test_langgraph_md"
   },
   "source": [
    "## 🧪 3. LangGraph 워크플로우 직접 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test_langgraph_code"
   },
   "outputs": [],
   "source": [
    "# LangGraph 워크플로우 단독 테스트\n",
    "def test_langgraph_workflow(topic: str):\n",
    "    \"\"\"LangGraph 워크플로우를 직접 실행하여 테스트\"\"\"\n",
    "\n",
    "    print(f\"🎯 테스트 주제: {topic}\")\n",
    "    print(\"\" + \"=\" * 60)\n",
    "\n",
    "    # 초기 상태 설정\n",
    "    initial_state = {\n",
    "        \"topic\": topic,\n",
    "        \"sub_questions\": [],\n",
    "        \"current_question\": \"\",\n",
    "        \"researched_data\": [],\n",
    "        \"final_report\": \"\",\n",
    "        \"step_count\": 0,\n",
    "    }\n",
    "\n",
    "    # 설정 (thread_id로 상태 추적)\n",
    "    config = {\"configurable\": {\"thread_id\": \"test_research_thread\"}}\n",
    "\n",
    "    # 워크플로우 실행\n",
    "    print(\"🚀 LangGraph 워크플로우 실행 시작...\\n\")\n",
    "\n",
    "    final_state = research_graph.invoke(initial_state, config)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"✅ LangGraph 워크플로우 실행 완료!\")\n",
    "    print(f\"📈 총 단계 수: {final_state.get('step_count', 0)}\")\n",
    "    print(f\"📋 조사된 질문 수: {len(final_state.get('researched_data', []))}\")\n",
    "    print(f\"📄 최종 보고서 길이: {len(final_state.get('final_report', ''))} 글자\")\n",
    "\n",
    "    return final_state\n",
    "\n",
    "\n",
    "# 테스트 실행\n",
    "test_topic = \"2024년 AI 에이전트 기술 트렌드\"\n",
    "langgraph_result = test_langgraph_workflow(test_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "langgraph_preview_code"
   },
   "outputs": [],
   "source": [
    "# LangGraph 결과 미리보기\n",
    "if langgraph_result and langgraph_result.get(\"final_report\"):\n",
    "    report = langgraph_result[\"final_report\"]\n",
    "    print(\"📋 LangGraph 최종 보고서 미리보기:\")\n",
    "    print(\"\" + \"=\" * 60)\n",
    "    print(report[:800] + \"...\" if len(report) > 800 else report)\n",
    "    print(\"\" + \"=\" * 60)\n",
    "else:\n",
    "    print(\"❌ LangGraph 실행 결과를 가져올 수 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adk_integration_md"
   },
   "source": [
    "## 🔧 4. ADK와 LangGraph 통합 - Workflow Agent 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adk_workflow_code"
   },
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai import types\n",
    "import asyncio\n",
    "import uuid\n",
    "\n",
    "\n",
    "def langgraph_research_tool(topic: str) -> dict:\n",
    "    \"\"\"LangGraph 워크플로우를 실행하는 ADK Tool\n",
    "\n",
    "    Args:\n",
    "        topic (str): 리서치할 주제\n",
    "\n",
    "    Returns:\n",
    "        dict: 다단계 리서치 결과\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"🔧 LangGraph Tool 실행: '{topic}'\")\n",
    "\n",
    "        # 초기 상태 설정\n",
    "        initial_state = {\n",
    "            \"topic\": topic,\n",
    "            \"sub_questions\": [],\n",
    "            \"current_question\": \"\",\n",
    "            \"researched_data\": [],\n",
    "            \"final_report\": \"\",\n",
    "            \"step_count\": 0,\n",
    "        }\n",
    "\n",
    "        # 고유한 thread_id 생성\n",
    "        thread_id = f\"adk_integration_{uuid.uuid4().hex[:8]}\"\n",
    "        config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "\n",
    "        # LangGraph 워크플로우 실행\n",
    "        final_state = research_graph.invoke(initial_state, config)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"topic\": topic,\n",
    "            \"steps_completed\": final_state.get(\"step_count\", 0),\n",
    "            \"questions_researched\": len(final_state.get(\"researched_data\", [])),\n",
    "            \"final_report\": final_state.get(\"final_report\", \"\"),\n",
    "            \"workflow_type\": \"LangGraph Multi-Step Research\",\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ LangGraph Tool 오류: {str(e)}\")\n",
    "        return {\"status\": \"error\", \"error_message\": f\"LangGraph 워크플로우 실행 중 오류: {str(e)}\"}\n",
    "\n",
    "\n",
    "# ADK Workflow Agent 생성\n",
    "workflow_agent = Agent(\n",
    "    name=\"langgraph_workflow_agent\",\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    description=\"LangGraph 기반 다단계 리서치 워크플로우를 실행하는 고급 Agent입니다.\",\n",
    "    instruction=\"\"\"당신은 복잡한 리서치 작업을 수행하는 전문 Agent입니다.\n",
    "\n",
    "사용자가 주제를 제시하면, langgraph_research_tool을 사용하여 다음과 같은 다단계 프로세스를 실행하세요:\n",
    "\n",
    "1. 주제 분석 및 세부 질문 생성\n",
    "2. 각 질문에 대한 체계적인 웹 검색\n",
    "3. 결과 종합 및 전문적인 보고서 작성\n",
    "\n",
    "이 도구는 LangGraph 워크플로우를 통해 상태를 유지하며 단계별로 작업을 수행합니다.\n",
    "결과를 받으면 사용자에게 요약과 함께 상세한 보고서를 제공하세요.\"\"\",\n",
    "    tools=[langgraph_research_tool],\n",
    ")\n",
    "\n",
    "print(\"✅ ADK Workflow Agent (LangGraph 통합)가 생성되었습니다!\")\n",
    "print(\"   🔗 통합: ADK Agent + LangGraph Tool\")\n",
    "print(\"   🧠 상태관리: LangGraph MemorySaver\")\n",
    "print(\"   🔄 워크플로우: 계획 → 조사(반복) → 종합\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adk_test_md"
   },
   "source": [
    "## 🚀 5. ADK Workflow Agent 실행 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "adk_test_code"
   },
   "outputs": [],
   "source": [
    "async def call_workflow_agent_async(agent, topic):\n",
    "    \"\"\"ADK Workflow Agent 비동기 실행 함수\"\"\"\n",
    "    session_service = InMemorySessionService()\n",
    "    session = await session_service.create_session(app_name=\"workflow_research_app\", user_id=\"workflow_user\")\n",
    "    runner = Runner(agent=agent, app_name=\"workflow_research_app\", session_service=session_service)\n",
    "\n",
    "    # 사용자 요청 메시지\n",
    "    prompt = f\"'{topic}' 주제에 대해 전문적인 다단계 리서치를 수행하고 상세한 보고서를 작성해주세요.\"\n",
    "    content = types.Content(role=\"user\", parts=[types.Part(text=prompt)])\n",
    "\n",
    "    # Agent 실행\n",
    "    events = runner.run_async(user_id=\"workflow_user\", session_id=session.id, new_message=content)\n",
    "\n",
    "    async for event in events:\n",
    "        if event.is_final_response():\n",
    "            return event.content.parts[0].text\n",
    "    return \"응답을 받지 못했습니다.\"\n",
    "\n",
    "\n",
    "# ADK Workflow Agent 실행\n",
    "workflow_topic = \"2024년 최신 멀티모달 AI 기술 동향\"\n",
    "print(f\"🎯 Workflow Agent 주제: {workflow_topic}\")\n",
    "print(\"🤖 ADK Workflow Agent (LangGraph 통합) 실행 중...\")\n",
    "print(\"   (계획 → 조사 → 종합 과정을 거쳐 2-3분 소요됩니다)\\n\")\n",
    "\n",
    "workflow_result = await call_workflow_agent_async(workflow_agent, workflow_topic)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"          ✅ ADK Workflow Agent (LangGraph 통합) 완료! ✅\")\n",
    "print(\"=\" * 80)\n",
    "print(workflow_result)\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adk_part2_conclusion_md"
   },
   "source": [
    "### 2.5. 결론: LLM Agent vs. Workflow Agent\n",
    "\n",
    "이번 실습을 통해 우리는 ADK가 제공하는 두 가지 핵심 Agent 유형을 모두 경험했습니다.\n",
    "\n",
    "| 구분 | `LLM Agent` (Part 1) | `Workflow Agent` (Part 2) |\n",
    "| :--- | :--- | :--- |\n",
    "| **상태 관리** | **Stateless** (기억 없음) | **Stateful** (기억 있음) |\n",
    "| **워크플로우** | **정적 (Static)**: 단일 LLM 호출 | **동적 (Dynamic)**: LangGraph 기반의 복잡한 흐름 제어 |\n",
    "| **주요 용도** | 간단한 단발성 작업 (계산, 단순 API 호출) | 여러 단계를 거치는 복잡한 작업 (리서치, 데이터 분석, 인간 개입) |\n",
    "| **핵심** | 빠르고 간단한 Tool 사용 | 유연하고 강력한 프로세스 자동화 |\n",
    "\n",
    "**최종 교훈:** ADK를 사용하면, 작업의 복잡성에 맞춰 가장 적합한 Agent 유형을 선택하여 개발할 수 있습니다. 간단한 작업은 `LLM Agent`로 빠르게, 복잡하고 상태 관리가 필요한 작업은 `Workflow Agent`와 `LangGraph`를 통해 정교하고 안정적으로 구축할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
