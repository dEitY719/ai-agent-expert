{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_intro_md"
   },
   "source": [
    "# [Lv4-Day2-Lab2] Building a Robust Agent: Human-in-the-Loop and Error Handling\n",
    "\n",
    "### 실습 목표\n",
    "이전 실습에서 만든 'Self-Correcting 리서처'는 스스로 계획하고 작업을 반복하는 놀라운 능력을 보여주었습니다. 하지만 실무 환경에서는 예측 불가능한 오류가 발생하거나, Agent의 자율적인 판단을 사람이 중간에 검토해야 하는 경우가 빈번합니다.\n",
    "\n",
    "이번 실습에서는 우리 Agent를 한 단계 더 진화시켜, **'인간과 협업'**하고 **'스스로 오류를 복구'**하는 **견고한(Robust) Agent**로 업그레이드합니다.\n",
    "\n",
    "1.  **Human-in-the-Loop 구현:** Agent가 세운 리서치 계획을 자동으로 실행하기 전에, 작업을 **일시정지(interrupt)**하고 사용자에게 **승인**을 요청하는 상호작용 지점을 만듭니다.\n",
    "2.  **에러 핸들링 및 재시도 로직 추가:** 웹 검색 Tool이 일시적인 오류로 실패했을 때, Agent가 멈추지 않고 **자동으로 재시도(Retry)**하는 복구 메커니즘을 `State`에 구현합니다.\n",
    "3.  **고급 제어 흐름 설계:** '성공', '실패', '인간의 승인' 등 다양한 시나리오에 따라 Agent가 각기 다른 행동을 하도록, 여러 갈래로 나뉘는 **복합적인 조건부 분기(Conditional Branching)**를 설계합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_setup_md"
   },
   "source": [
    "### 0. 사전 준비: 라이브러리 및 API 키\n",
    "이전 실습과 동일한 환경에서 진행합니다. 혹시 세션이 초기화되었다면 아래 셀들을 다시 실행해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "robust_install_code"
   },
   "outputs": [],
   "source": [
    "# !pip install langgraph langchain langchain_google_genai langchain_community beautifulsoup4 tavily-python -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "robust_api_keys_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 API 키가 성공적으로 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# API 키 설정\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDVYEpxB86k5-Oi2BApqTr47nnGJ0BwkOc\"\n",
    "\n",
    "# Tavily AI API 키 설정 (웹 검색 Tool용)\n",
    "if \"TAVILY_API_KEY\" not in os.environ:\n",
    "    os.environ[\"TAVILY_API_KEY\"] = \"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\"\n",
    "\n",
    "print(\"✅ 모든 API 키가 성공적으로 설정되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_state_md"
   },
   "source": [
    "### 1. State 확장: 재시도 횟수(Retry Count) 추가\n",
    "에러 핸들링을 위해 기존 `ResearchAgentState`에 `retries`라는 새로운 키를 추가합니다. 이 값은 특정 작업의 실패 횟수를 추적하는 데 사용됩니다. 만약 재시도 횟수가 특정 임계값(예: 3회)을 초과하면, Agent가 무한 루프에 빠지지 않고 다른 조치를 취하도록 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "robust_state_code"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "\n",
    "\n",
    "# 이전 실습의 State를 그대로 가져와 'retries' 키만 추가합니다.\n",
    "class RobustAgentState(TypedDict):\n",
    "    topic: str\n",
    "    sub_questions: List[str]\n",
    "    researched_data: Annotated[list, operator.add]\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    retries: int  # 재시도 횟수를 추적하기 위한 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_nodes_md"
   },
   "source": [
    "### 2. Tool 및 노드 함수 재정의\n",
    "이전 실습에서 사용했던 Tool과 노드 함수들을 그대로 가져옵니다. 단, 에러 핸들링을 시뮬레이션하기 위해 `research_step` 함수에 약간의 수정을 가할 것입니다 (실제 구현에서는 Tool 자체의 오류를 `try-except`로 잡게 됩니다)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "robust_nodes_code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162/1636765745.py:6: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(max_results=2)\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Tool 및 LLM 초기화\n",
    "web_search_tool = TavilySearchResults(max_results=2)\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\", temperature=0)\n",
    "\n",
    "\n",
    "class SubQuestions(BaseModel):\n",
    "    questions: List[str] = Field(description=\"생성된 세부 질문들의 리스트\")\n",
    "\n",
    "\n",
    "structured_llm = llm.with_structured_output(SubQuestions)\n",
    "\n",
    "\n",
    "# 노드 함수들 (이전 실습과 대부분 동일)\n",
    "def plan_step(state: RobustAgentState):\n",
    "    print(\"--- 🧠 [Node] 계획 수립 중... ---\")\n",
    "    prompt = f\"'{state['topic']}'이라는 주제에 대한 리서치 보고서를 작성하려고 합니다. 이 주제를 3개의 핵심적인 세부 질문으로 분해해주세요.\"\n",
    "    sub_questions_pydantic = structured_llm.invoke(prompt)\n",
    "    sub_questions = sub_questions_pydantic.questions\n",
    "    print(f\"생성된 세부 질문: {sub_questions}\")\n",
    "    return {\"sub_questions\": sub_questions, \"researched_data\": [], \"retries\": 0}\n",
    "\n",
    "\n",
    "def research_step(state: RobustAgentState):\n",
    "    print(\"--- 🛠️ [Node] 자료 조사 중... ---\")\n",
    "    current_questions = state[\"sub_questions\"]\n",
    "    if not current_questions:\n",
    "        return {}\n",
    "\n",
    "    question_to_research = current_questions[0]\n",
    "    remaining_questions = current_questions[1:]\n",
    "    current_retry = state.get(\"retries\", 0)\n",
    "    print(f\"조사할 질문: '{question_to_research}' (재시도 {current_retry}회)\")\n",
    "\n",
    "    try:\n",
    "        # 첫 번째 질문의 첫 번째 시도에서만 에러 발생\n",
    "        is_first_question = len(remaining_questions) == 2  # 3개 중 첫 번째\n",
    "        if current_retry == 0 and is_first_question:\n",
    "            print(\"🔴 첫 번째 시도 - 의도적 에러 발생\")\n",
    "            raise ValueError(\"의도적으로 발생시킨 API 네트워크 오류입니다.\")\n",
    "\n",
    "        researched_info = web_search_tool.invoke(question_to_research)\n",
    "        print(f\"✅ 조사 성공! (재시도 {current_retry}회 후)\")\n",
    "        return {\n",
    "            \"sub_questions\": remaining_questions,\n",
    "            \"researched_data\": [(question_to_research, researched_info)],\n",
    "            \"retries\": 0,  # 성공 시 재시도 횟수 초기화\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"🔴 조사 실패: {e}\")\n",
    "        new_retry_count = current_retry + 1\n",
    "        print(f\"재시도 횟수: {new_retry_count}\")\n",
    "        return {\n",
    "            \"retries\": new_retry_count\n",
    "            # sub_questions는 그대로 유지 (덮어쓰지 않음)\n",
    "        }\n",
    "\n",
    "\n",
    "def summarize_step(state: RobustAgentState):\n",
    "    print(\"--- 📝 [Node] 최종 보고서 작성 중... ---\")\n",
    "    research_summary = \"\\n\".join([f\"질문: {q}\\n답변: {a}\" for q, a in state[\"researched_data\"]])\n",
    "    prompt = f\"다음은 '{state['topic']}'에 대한 리서치 결과입니다.\\n\\n{research_summary}\\n\\n이 내용을 바탕으로 최종 종합 보고서를 작성해주세요.\"\n",
    "    final_report = llm.invoke(prompt)\n",
    "    return {\"messages\": [final_report]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_graph_md"
   },
   "source": [
    "### 3. Human-in-the-Loop를 위한 그래프 설계\n",
    "이제 `LangGraph`의 진정한 묘미를 경험할 시간입니다. 이전보다 훨씬 복잡한, '인간의 개입'과 '오류 처리'가 포함된 워크플로우를 구축합니다.\n",
    "\n",
    "1.  **일시정지(Interrupt) 추가:** `plan` 노드 다음에 `add_edge(..., END)` 대신 `Interrupt(before=[\"research\"])`를 사용하여, `research` 노드 실행 직전에 그래프를 멈추도록 설정합니다. 이것이 바로 Human-in-the-loop의 핵심입니다.\n",
    "2.  **복합 라우터(Router) 함수:** `should_continue` 함수를 개선하여 3가지 상황을 판단하도록 합니다.\n",
    "    - 재시도 횟수가 2회를 초과하면 -> `give_up` (포기)\n",
    "    - 남은 질문이 있으면 -> `continue_research` (조사 계속)\n",
    "    - 남은 질문이 없으면 -> `summarize` (종합)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "robust_graph_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Part 2: Robust 리서처 Agent 그래프가 성공적으로 생성되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "\n",
    "def should_continue(state: RobustAgentState):\n",
    "    print(\"--- 🤔 [Router] 다음 단계 판단 중... ---\")\n",
    "    if state.get(\"retries\", 0) > 2:\n",
    "        print(\"판단: 재시도 횟수 초과. 조사를 포기합니다.\")\n",
    "        return \"give_up\"\n",
    "    if state[\"sub_questions\"]:\n",
    "        print(\"판단: 남은 질문이 있으므로 조사를 계속합니다.\")\n",
    "        return \"continue_research\"\n",
    "    else:\n",
    "        print(\"판단: 모든 질문에 대한 조사가 완료되어 종합 단계로 넘어갑니다.\")\n",
    "        return \"summarize\"\n",
    "\n",
    "\n",
    "graph_robust = StateGraph(RobustAgentState)\n",
    "graph_robust.add_node(\"plan\", plan_step)\n",
    "graph_robust.add_node(\"research\", research_step)\n",
    "graph_robust.add_node(\"summary\", summarize_step)\n",
    "\n",
    "graph_robust.set_entry_point(\"plan\")\n",
    "graph_robust.add_edge(\"plan\", \"research\")\n",
    "\n",
    "graph_robust.add_conditional_edges(\n",
    "    \"research\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue_research\": \"research\",\n",
    "        \"summarize\": \"summary\",\n",
    "        \"give_up\": END,  # 'give_up' 신호를 받으면 바로 워크플로우 종료\n",
    "    },\n",
    ")\n",
    "graph_robust.add_edge(\"summary\", END)\n",
    "\n",
    "# interrupt_before 옵션으로 research 노드 실행 전에 일시정지\n",
    "chain_robust = graph_robust.compile(\n",
    "    checkpointer=memory, interrupt_before=[\"research\"]  # research 노드 실행 전에 interrupt\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Part 2: Robust 리서처 Agent 그래프가 성공적으로 생성되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "robust_run_md"
   },
   "source": [
    "### 4. Robust Agent 실행 및 상호작용\n",
    "이제 새로운 Agent를 실행하고 그 과정을 관찰해 봅시다. `chain.invoke`를 실행하면, 계획 수립 후 Agent가 멈추고 사용자 입력을 기다립니다. `chain.update_state`를 사용하여 사용자의 승인('yes')을 전달하면, Agent는 멈췄던 지점부터 작업을 재개합니다.\n",
    "\n",
    "실행 로그를 통해 첫 번째 조사에서 의도된 오류가 발생하고, Agent가 자동으로 재시도 상태로 진입한 뒤, 성공적으로 작업을 이어나가는 전 과정을 관찰할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "robust_run_code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 🚀 Agent 실행 시작 ---\n",
      "--- 🧠 [Node] 계획 수립 중... ---\n",
      "생성된 세부 질문: ['LangGraph와 CrewAI의 핵심 아키텍처와 설계 철학은 어떻게 다른가요?', '두 프레임워크에서 에이전트 개발 프로세스와 맞춤 설정 기능은 어떻게 비교되나요?', 'LangGraph와 CrewAI가 각각 가장 적합한 특정 사용 사례나 애플리케이션 유형은 무엇인가요?']\n",
      "\n",
      "--- ⏸️ Agent 일시정지: 사용자 승인 대기 중 ---\n",
      "생성된 계획: ['LangGraph와 CrewAI의 핵심 아키텍처와 설계 철학은 어떻게 다른가요?', '두 프레임워크에서 에이전트 개발 프로세스와 맞춤 설정 기능은 어떻게 비교되나요?', 'LangGraph와 CrewAI가 각각 가장 적합한 특정 사용 사례나 애플리케이션 유형은 무엇인가요?']\n",
      "\n",
      "이 계획대로 리서치를 진행하시겠습니까? (yes/no): yes\n",
      "\n",
      "--- ▶️ Agent 작업 재개 ---\n",
      "--- 🛠️ [Node] 자료 조사 중... ---\n",
      "조사할 질문: 'LangGraph와 CrewAI의 핵심 아키텍처와 설계 철학은 어떻게 다른가요?' (재시도 0회)\n",
      "🔴 첫 번째 시도 - 의도적 에러 발생\n",
      "🔴 조사 실패: 의도적으로 발생시킨 API 네트워크 오류입니다.\n",
      "재시도 횟수: 1\n",
      "--- 🤔 [Router] 다음 단계 판단 중... ---\n",
      "판단: 남은 질문이 있으므로 조사를 계속합니다.\n",
      "Event: ['research']\n",
      "Event: ['__interrupt__']\n",
      "⚠️ 추가 interrupt 발생 - 계속 진행\n",
      "--- 🛠️ [Node] 자료 조사 중... ---\n",
      "조사할 질문: 'LangGraph와 CrewAI의 핵심 아키텍처와 설계 철학은 어떻게 다른가요?' (재시도 1회)\n",
      "✅ 조사 성공! (재시도 1회 후)\n",
      "--- 🤔 [Router] 다음 단계 판단 중... ---\n",
      "판단: 남은 질문이 있으므로 조사를 계속합니다.\n",
      "Event: ['research']\n",
      "Event: ['__interrupt__']\n",
      "⚠️ 추가 interrupt 발생 - 계속 진행\n",
      "--- 🛠️ [Node] 자료 조사 중... ---\n",
      "조사할 질문: '두 프레임워크에서 에이전트 개발 프로세스와 맞춤 설정 기능은 어떻게 비교되나요?' (재시도 0회)\n",
      "✅ 조사 성공! (재시도 0회 후)\n",
      "--- 🤔 [Router] 다음 단계 판단 중... ---\n",
      "판단: 남은 질문이 있으므로 조사를 계속합니다.\n",
      "Event: ['research']\n",
      "Event: ['__interrupt__']\n",
      "⚠️ 추가 interrupt 발생 - 계속 진행\n",
      "--- 🛠️ [Node] 자료 조사 중... ---\n",
      "조사할 질문: 'LangGraph와 CrewAI가 각각 가장 적합한 특정 사용 사례나 애플리케이션 유형은 무엇인가요?' (재시도 0회)\n",
      "✅ 조사 성공! (재시도 0회 후)\n",
      "--- 🤔 [Router] 다음 단계 판단 중... ---\n",
      "판단: 모든 질문에 대한 조사가 완료되어 종합 단계로 넘어갑니다.\n",
      "Event: ['research']\n",
      "--- 📝 [Node] 최종 보고서 작성 중... ---\n",
      "Event: ['summary']\n",
      "✅ 최종 보고서가 완성되었습니다!\n",
      "\n",
      "================================================================================\n",
      "                           ✅ 최종 보고서 ✅\n",
      "================================================================================\n",
      "## LangGraph vs. CrewAI: 종합 비교 분석 보고서\n",
      "\n",
      "제공된 리서치 결과를 바탕으로 LangGraph와 CrewAI의 주요 차이점을 종합하여 다음과 같이 보고서를 작성합니다.\n",
      "\n",
      "### 1. 핵심 아키텍처 및 설계 철학\n",
      "\n",
      "두 프레임워크는 AI 에이전트를 구축한다는 공통점을 가지지만, 근본적인 접근 방식과 설계 철학에서 뚜렷한 차이를 보입니다.\n",
      "\n",
      "#### **LangGraph: 상태 기반 그래프(Graph) 아키텍처와 인간 주도적(Human-Driven) 설계**\n",
      "\n",
      "*   **아키텍처:** LangGraph는 LangChain의 확장 기능으로, 상태(State)를 가진 그래프(Graph) 구조를 기반으로 합니다. 각 노드(Node)는 작업 단위(에이전트 또는 함수)를 나타내고, 엣지(Edge)는 노드 간의 제어 흐름을 결정합니다. 이를 통해 복잡한 워크플로우를 시각적으로 구조화하고, 순환(Cycle)이나 조건부 분기 등 정교한 로직을 구현할 수 있습니다.\n",
      "*   **설계 철학:** **'인간 주도적(Human-Driven) 접근'**을 취합니다. 개발자가 코드를 통해 워크플로우의 모든 단계를 명확하게 정의하고 제어하는 것에서 시작하여 점차 자율성을 부여하는 방식입니다. 이는 복잡하지만 목표가 명확한 작업을 수행할 때, 개발자가 데이터 흐름과 에이전트의 의사결정 과정을 세밀하게 제어하고 싶을 때 강력한 장점을 가집니다.\n",
      "\n",
      "#### **CrewAI: 역할 기반 멀티 에이전트 아키텍처와 자율 협업 중심 설계**\n",
      "\n",
      "*   **아키텍처:** CrewAI는 처음부터 여러 에이전트의 '협업'에 초점을 맞춘 고수준(High-level) 프레임워크입니다. **에이전트(Agent), 태스크(Task), 크루(Crew)**라는 세 가지 핵심 요소로 구성됩니다. 각 에이전트는 특정 역할(예: 리서처, 작가)과 목표를 부여받고, 태스크는 수행할 작업을 정의합니다. 크루는 이 에이전트와 태스크를 묶어 전체적인 워크플로우(예: 순차적, 계층적)를 오케스트레이션합니다.\n",
      "*   **설계 철학:** **'멀티 에이전트 프레임워크로 시작'**하는 접근 방식을 따릅니다. 자율적인 에이전트들이 팀을 이루어 협업하는 개념에서 출발하여, 사용자가 필요에 따라 커스터마이징할 수 있도록 지원합니다. 이는 마치 각기 다른 전문성을 가진 팀원들에게 프로젝트를 맡기는 것과 유사합니다.\n",
      "\n",
      "| 구분 | **LangGraph** | **CrewAI** |\n",
      "| :--- | :--- | :--- |\n",
      "| **핵심 개념** | 상태(State), 노드(Node), 엣지(Edge) | 에이전트(Agent), 태스크(Task), 크루(Crew) |\n",
      "| **아키텍처** | 상태 기반 그래프(Graph) | 역할 기반 멀티 에이전트 협업 |\n",
      "| **설계 철학** | 인간 주도적 (코드로 시작 → 자율성 부여) | 자율 협업 중심 (멀티 에이전트로 시작 → 커스터마이징) |\n",
      "| **제어 수준** | 낮고 세밀함 (Low-level, Fine-grained) | 높고 추상적임 (High-level, Abstract) |\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 에이전트 개발 프로세스 및 맞춤 설정\n",
      "\n",
      "아키텍처의 차이는 개발 경험과 맞춤 설정 방식에 직접적인 영향을 미칩니다.\n",
      "\n",
      "*   **LangGraph:**\n",
      "    *   **개발 프로세스:** 더 가파른 학습 곡선(Steeper learning curve)을 요구합니다. 개발자는 Python 코드를 통해 그래프의 각 노드와 엣지의 작동 방식을 직접 정의해야 합니다. 이는 초기 설정이 복잡하고 시간이 더 걸릴 수 있음을 의미합니다.\n",
      "    *   **맞춤 설정:** 매우 높은 유연성과 강력한 맞춤 설정 기능을 제공합니다. 에이전트의 작동 방식, 상태 관리, 제어 흐름 등 모든 요소를 세밀하게 조정(Fine-tuning)할 수 있어, 독창적이고 복잡한 에이전트 시스템을 구축하는 데 유리합니다.\n",
      "\n",
      "*   **CrewAI:**\n",
      "    *   **개발 프로세스:** 사용자 친화적이며 직관적입니다. 개발자는 각 에이전트의 역할, 배경 이야기(backstory), 목표와 같은 추상적인 개념을 정의하고, 이를 태스크와 연결하기만 하면 기본적인 협업 워크플로우를 빠르게 구성할 수 있습니다. 코딩 경험이 적은 사용자도 쉽게 접근할 수 있습니다.\n",
      "    *   **맞춤 설정:** 고수준 프레임워크이므로 LangGraph만큼 세밀한 제어는 어렵지만, 에이전트의 역할, 사용할 도구(Tool), 협업 프로세스(순차/계층) 등을 정의하며 충분한 맞춤 설정이 가능합니다. 특히 '플로우(Flow)' 기능을 통해 사용자가 직접 작업 순서를 정하는 등 제어 기능을 강화하고 있습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. 주요 사용 사례 및 적용 분야\n",
      "\n",
      "두 프레임워크는 각각의 장점에 따라 서로 다른 유형의 애플리케이션에 더 적합합니다.\n",
      "\n",
      "*   **LangGraph가 적합한 경우:**\n",
      "    *   **목표가 명확한 복잡한 워크플로우:** 에이전트 간의 상호작용과 데이터 흐름을 명시적으로 시각화하고 제어해야 하는 복잡한 문제 해결에 유리합니다.\n",
      "    *   **엔터프라이즈급 데이터 처리:** 대규모 데이터를 여러 단계에 걸쳐 효율적으로 처리하고 관계를 관리해야 하는 엔터프라이즈 환경에 적합합니다.\n",
      "    *   **상태 추적이 중요한 애플리케이션:** 사용자와의 긴 대화나 다단계 작업을 처리하며 지속적으로 상태를 추적하고 반영해야 할 때 강력한 성능을 발휘합니다.\n",
      "\n",
      "*   **CrewAI가 적합한 경우:**\n",
      "    *   **팀워크 기반의 자동화:** 여러 전문 분야의 협업이 필요한 작업을 자동화하는 데 특화되어 있습니다.\n",
      "        *   **콘텐츠 제작:** 리서처, 작가, 편집자 에이전트가 협력하여 기사나 보고서를 작성\n",
      "        *   **이메일 관리 자동화:** 이메일 분석, 관련 정보 조사, 답장 초안 작성을 각기 다른 에이전트가 처리\n",
      "        *   **주식 분석 및 투자 추천:** 데이터 분석가, 재무 전문가, 리포터 에이전트가 협력하여 종합적인 분석 보고서 생성\n",
      "    *   **신속한 프로토타이핑:** 사용자 친화적인 구조 덕분에 비즈니스 환경에서 AI 에이전트 시스템을 빠르게 프로토타이핑하고 배포하는 데 매우 유용합니다.\n",
      "\n",
      "### 결론\n",
      "\n",
      "**LangGraph**는 **'정교한 제어와 유연성'**을 중시하는 개발자를 위한 로우레벨(Low-level) 프레임워크입니다. 복잡한 워크플로우를 밑바닥부터 설계하고 모든 단계를 완벽하게 통제하고 싶을 때 최적의 선택입니다.\n",
      "\n",
      "반면, **CrewAI**는 **'신속한 개발과 자율적인 협업'**에 초점을 맞춘 하이레벨(High-level) 프레임워크입니다. 특정 역할을 수행하는 에이전트 팀을 빠르게 구성하여 비즈니스 문제를 해결하고자 할 때 가장 효과적인 도구입니다.\n",
      "\n",
      "따라서 어떤 프레임워크를 선택할지는 해결하려는 문제의 복잡성, 필요한 제어 수준, 그리고 개발 속도 등 프로젝트의 요구사항에 따라 결정해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "session_id_part2 = str(uuid.uuid4())\n",
    "config_robust = {\"configurable\": {\"thread_id\": session_id_part2}}\n",
    "\n",
    "user_topic = \"LangGraph와 CrewAI의 주요 차이점은 무엇인가?\"\n",
    "\n",
    "initial_state = {\"messages\": [HumanMessage(content=\"리서치를 시작합니다.\")], \"topic\": user_topic}\n",
    "\n",
    "# 1. 첫 번째 실행: 계획 수립 후 '일시정지' 됩니다.\n",
    "print(\"--- 🚀 Agent 실행 시작 ---\")\n",
    "paused_state = chain_robust.invoke(initial_state, config=config_robust)\n",
    "print(\"\\n--- ⏸️ Agent 일시정지: 사용자 승인 대기 중 ---\")\n",
    "print(f\"생성된 계획: {paused_state['sub_questions']}\")\n",
    "\n",
    "# 2. Human-in-the-Loop: 사용자가 계획을 검토하고 승인합니다.\n",
    "user_approval = input(\"\\n이 계획대로 리서치를 진행하시겠습니까? (yes/no): \")\n",
    "\n",
    "if user_approval.lower() == \"yes\":\n",
    "    print(\"\\n--- ▶️ Agent 작업 재개 ---\")\n",
    "\n",
    "    # 모든 이벤트를 처리하면서 최종 상태 추적\n",
    "    final_state = None\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        try:\n",
    "            for event in chain_robust.stream(None, config=config_robust):\n",
    "                print(f\"Event: {list(event.keys())}\")\n",
    "\n",
    "                # '__interrupt__' 이벤트가 나오면 다시 재개\n",
    "                if \"__interrupt__\" in event:\n",
    "                    print(\"⚠️ 추가 interrupt 발생 - 계속 진행\")\n",
    "                    continue\n",
    "\n",
    "                # 각 노드의 출력 확인\n",
    "                for node_name, node_output in event.items():\n",
    "                    if node_name == \"summary\" and isinstance(node_output, dict):\n",
    "                        if \"messages\" in node_output and node_output[\"messages\"]:\n",
    "                            final_state = node_output\n",
    "                            completed = True\n",
    "                            print(f\"✅ 최종 보고서가 완성되었습니다!\")\n",
    "                            break\n",
    "\n",
    "                if completed:\n",
    "                    break\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ 스트림 처리 중 오류: {e}\")\n",
    "            break\n",
    "\n",
    "    # 최종 결과 출력\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"                           ✅ 최종 보고서 ✅\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if final_state and \"messages\" in final_state and final_state[\"messages\"]:\n",
    "        print(final_state[\"messages\"][-1].content)\n",
    "    else:\n",
    "        # 대안: 현재 전체 상태에서 확인\n",
    "        current_state = chain_robust.get_state(config_robust)\n",
    "        if current_state.values.get(\"messages\"):\n",
    "            # 초기 메시지가 아닌 실제 보고서 찾기\n",
    "            messages = current_state.values[\"messages\"]\n",
    "            for msg in reversed(messages):\n",
    "                if msg.content != \"리서치를 시작합니다.\" and len(msg.content) > 50:\n",
    "                    print(msg.content)\n",
    "                    break\n",
    "            else:\n",
    "                print(\"⚠️ 최종 보고서를 찾을 수 없습니다.\")\n",
    "        else:\n",
    "            print(\"⚠️ 메시지가 없습니다.\")\n",
    "\n",
    "else:\n",
    "    print(\"사용자가 계획을 거부하여 작업을 중단합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKdYXhvR1Mgq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
