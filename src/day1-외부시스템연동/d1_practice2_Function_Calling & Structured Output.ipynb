{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ojp051ph--zk"
   },
   "source": [
    "# Section 0: 실습 사전 준비\n",
    "### 0.1. 실습 목표\n",
    "이번 시간에는 AI Agent가 외부 시스템과 소통하는 핵심 기술인 **Tool Calling**과 **Structured Output**에 대해 깊이 있게 학습합니다. 수강생 여러분은 이번 실습을 통해 다음과 같은 역량을 확보하게 됩니다.\n",
    "\n",
    "1.  **Tool Calling 원리 체득:** 사용자의 자연어 명령을 LLM이 분석하여, 시스템이 실행할 수 있는 구조화된 함수 호출(Function Call)로 변환하는 핵심 메커니즘을 이해합니다. 이는 Agent가 단순히 텍스트만 생성하는 것을 넘어, 실제 '행동'을 수행하게 만드는 첫걸음입니다.\n",
    "2.  **병렬 처리(Parallel Calling) 구현:** \"오늘 날씨와 주가 둘 다 알려줘\"와 같은 사용자의 복합적인 질문에 대응하기 위해, 여러 함수를 동시에 호출하는 병렬 처리 방식을 구현합니다. 이를 통해 네트워크 지연 시간을 최소화하고 응답 속도를 향상시키는 실무적인 최적화 기법을 익힙니다.\n",
    "3.  **구조화된 출력(Structured Output) 제어:** LLM의 자유로운 텍스트 출력을 Pydantic 모델을 활용하여 우리가 원하는 특정 JSON 구조로 '강제'하는 방법을 학습합니다. 이는 LLM의 응답을 다른 시스템(데이터베이스, 프론트엔드 등)과 안정적으로 연동하기 위한 필수 기술입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-6GzQVt_SWP"
   },
   "source": [
    "### 0.2. 라이브러리 설치\n",
    "이번 실습에 필요한 라이브러리들을 설치합니다. 각 라이브러리의 역할은 다음과 같습니다.\n",
    "\n",
    "- `google-generativeai`: Google의 Gemini API를 Python 환경에서 사용하기 위한 공식 라이브러리입니다.\n",
    "- `pydantic`: 데이터 유효성 검사 및 구조 정의를 위한 라이브러리입니다. LLM의 출력을 우리가 원하는 클래스(Class) 형태로 정확하게 변환하고 검증하는 데 사용됩니다.\n",
    "- `instructor`: LLM의 출력을 Pydantic 모델로 강제하는 핵심 라이브러리입니다. 복잡한 후처리 코드 없이도 LLM의 응답을 신뢰할 수 있는 데이터 구조로 만들어줍니다.\n",
    "- `finnhub-python`: 실시간 주식 데이터를 제공하는 Finnhub API를 쉽게 사용하기 위한 Python 클라이언트입니다.\n",
    "- `arxiv`: arXiv.org의 논문 데이터를 프로그래밍 방식으로 검색하고 메타데이터를 가져올 수 있는 라이브러리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T_ph8bMWFGSN"
   },
   "outputs": [],
   "source": [
    "# !pip install google-generativeai \"pydantic>=2.0\" instructor finnhub-python arxiv jsonref -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YnGS2jWU_r2a"
   },
   "source": [
    "### 0.3. API 키 발급 및 보안 설정\n",
    "이번 실습에서는 총 3개의 무료 API 키가 필요합니다.\n",
    "\n",
    "**1. Google AI Studio API Key (LLM용):**\n",
    "- [Google AI Studio](https://aistudio.google.com/app/apikey)에 접속하여 API 키를 생성합니다.\n",
    "- `GOOGLE_API_KEY` 라는 이름으로 저장합니다\n",
    "\n",
    "**2. OpenWeatherMap API Key (날씨 정보 Tool용):**\n",
    "- [OpenWeatherMap](https://openweathermap.org/api)에 가입하고 로그인합니다.\n",
    "- API Keys 탭에서 Default 키를 복사합니다.\n",
    "- `OPENWEATHER_API_KEY` 라는 이름으로 저장합니다\n",
    "\n",
    "**3. Finnhub API Key (주식 정보 Tool용):**\n",
    "- [Finnhub](https://finnhub.io/register)에 가입하고 로그인합니다.\n",
    "- 대시보드에서 API Key를 복사합니다. (무료 플랜으로 충분합니다.)\n",
    "- `FINNHUB_API_KEY` 라는 이름으로 저장합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "FzMXqpWr_Rp-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 모든 API 키가 성공적으로 설정되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "from getpass import getpass\n",
    "\n",
    "# API 키 설정\n",
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass(\"Google AI Studio API 키를 입력하세요: \")\n",
    "\n",
    "if \"OPENWEATHER_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENWEATHER_API_KEY\"] = getpass(\"OPENWEATHER_API_KEY 를 입력하세요: \")\n",
    "\n",
    "if \"FINNHUB_API_KEY\" not in os.environ:\n",
    "    os.environ[\"FINNHUB_API_KEY\"] = getpass(\"FINNHUB_API_KEY 를 입력하세요: \")\n",
    "\n",
    "# google-generativeai 라이브러리에 API 키를 설정합니다.\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "print(\"✅ 모든 API 키가 성공적으로 설정되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flzuifFsR8Ld"
   },
   "source": [
    "# Section 1. 실제 외부 API를 활용한 Tool Calling 실습\n",
    "### 1.1. Agent가 사용할 실제 Tool 정의\n",
    "Agent가 외부 세계와 상호작용할 수 있도록, 실제 외부 API를 호출하는 두 개의 함수를 Tool로 정의합니다. 각 함수는 명확한 역할과 입출력 구조를 가집니다.\n",
    "\n",
    "- `get_current_weather`: OpenWeatherMap API를 호출하여 특정 도시의 실시간 날씨 정보를 가져옵니다.\n",
    "- `get_stock_price`: Finnhub API를 호출하여 특정 종목 코드의 현재 주가를 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "C9UZkggySN7X"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import finnhub\n",
    "\n",
    "\n",
    "def get_return_bigger(valueA: float, valueB: float) -> float:\n",
    "    \"\"\"두 수를 받아서 더 큰 수를 반환한다.\"\"\"\n",
    "    return max(valueA, valueB)\n",
    "\n",
    "\n",
    "def get_current_weather(location: str, unit: str = \"celsius\") -> str:\n",
    "    \"\"\"OpenWeatherMap API를 사용하여 주어진 도시의 현재 날씨 정보를 가져옵니다.\"\"\"\n",
    "    api_key = os.environ[\"OPENWEATHER_API_KEY\"]\n",
    "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}&units=metric\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        weather_info = {\n",
    "            \"location\": data[\"name\"],\n",
    "            \"temperature\": data[\"main\"][\"temp\"],\n",
    "            \"unit\": \"celsius\",\n",
    "            \"forecast\": data[\"weather\"][0][\"description\"],\n",
    "        }\n",
    "        return json.dumps(weather_info, ensure_ascii=False)\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        return f\"HTTP 오류: {http_err}\"\n",
    "    except Exception as e:\n",
    "        return f\"알 수 없는 오류: {e}\"\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str) -> str:\n",
    "    \"\"\"Finnhub API를 사용하여 주어진 종목 코드(symbol)의 현재 주가를 가져옵니다.\"\"\"\n",
    "    api_key = os.environ[\"FINNHUB_API_KEY\"]\n",
    "    finnhub_client = finnhub.Client(api_key=api_key)\n",
    "    try:\n",
    "        quote = finnhub_client.quote(symbol)\n",
    "        if quote.get(\"c\") is None or quote.get(\"c\") == 0:\n",
    "            return f\"오류: '{symbol}'에 대한 주가 정보를 찾을 수 없습니다.\"\n",
    "        stock_info = {\"symbol\": symbol, \"price\": quote[\"c\"], \"currency\": \"USD\"}\n",
    "        return json.dumps(stock_info)\n",
    "    except Exception as e:\n",
    "        return f\"API 호출 중 오류 발생: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NWnf3EjSVcc"
   },
   "source": [
    "### 1.2. LLM을 위한 Tool 명세(Schema) 정의\n",
    "LLM은 코드 자체를 이해하지 못합니다. 따라서 우리가 만든 함수를 LLM이 사용할 수 있도록, 각 함수의 기능과 사용법을 설명하는 '사용 설명서', 즉 **명세(Schema)**를 만들어 전달해야 합니다.\n",
    "\n",
    "이 명세서의 `description` 필드가 얼마나 명확하고 상세한지에 따라 LLM의 Tool 선택 및 사용 능력이 크게 좌우됩니다. `google-generativeai` 라이브러리의 `Tool`과 `FunctionDeclaration`을 사용하여 이 명세를 체계적으로 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I0F1PDwRXoFf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Tool 명세가 성공적으로 정의되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from google.generativeai.types import Tool, FunctionDeclaration\n",
    "\n",
    "get_return_bigger_func = FunctionDeclaration(\n",
    "    name=\"get_return_bigger\",\n",
    "    description=\"두 수를 받아서 더 큰 수를 반환한다.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"valueA\": {\"type\": \"number\", \"description\": \"크기 비교할 첫번째 값\"},\n",
    "            \"valueB\": {\"type\": \"number\", \"description\": \"크기 비교할 두번째 값\"},\n",
    "        },\n",
    "        \"required\": [\"valueA\", \"valueB\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "get_current_weather_func = FunctionDeclaration(\n",
    "    name=\"get_current_weather\",\n",
    "    description=\"사용자가 지정한 도시의 현재 날씨 정보를 가져옵니다.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"location\": {\"type\": \"string\", \"description\": \"날씨를 조회할 도시의 영어 이름 (예: Seoul, Busan)\"},\n",
    "            \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"], \"description\": \"온도 단위\"},\n",
    "        },\n",
    "        \"required\": [\"location\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "get_stock_price_func = FunctionDeclaration(\n",
    "    name=\"get_stock_price\",\n",
    "    description=\"미국 증시에 상장된 주식의 현재 가격을 티커 심볼(ticker symbol)을 사용하여 가져옵니다.\",\n",
    "    parameters={\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"symbol\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"주가를 조회할 주식의 티커 심볼 (예: Apple Inc.는 'AAPL', Google은 'GOOGL')\",\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"symbol\"],\n",
    "    },\n",
    ")\n",
    "\n",
    "agent_tools = Tool(\n",
    "    function_declarations=[\n",
    "        get_return_bigger_func,\n",
    "        get_current_weather_func,\n",
    "        get_stock_price_func,\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"✅ Tool 명세가 성공적으로 정의되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Bc-QEzAYPFF"
   },
   "source": [
    "### 1.3. Agent Executor 로직 구현\n",
    "이제 LLM의 '제안'을 받아 실제로 함수를 실행하고, 그 결과를 다시 LLM에게 전달하여 최종 답변을 생성하는 **Agent의 핵심 실행 로직(Executor)**을 구현합니다. 이 2-Step 프로세스는 모든 Agent 시스템의 가장 기본적인 작동 원리입니다.\n",
    "\n",
    "1.  **Suggestion (제안):** `사용자 질문` + `Tool 명세` → LLM → `함수 호출 제안(JSON)`\n",
    "2.  **Execution (실행):** `함수 호출 제안(JSON)` → 개발자 코드(Executor) → `실제 함수 실행` → `실행 결과`\n",
    "3.  **Final Answer (최종 답변):** `전체 대화 기록` + `실행 결과` → LLM → `최종 사용자 답변(자연어)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xPNwZHdcSSCc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 사용자 질문: 1.1111과 1.9 중에 더 큰 수 뭐야?\n",
      "🧠 LLM의 제안: get_return_bigger_func({'valueB': 1.9, 'valueA': 1.1111})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'오류: 모델이 제안한 함수를 찾을 수 없습니다.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-pro\", tools=[agent_tools])\n",
    "\n",
    "\n",
    "def agent_executor(prompt: str):\n",
    "    print(f\"🚀 사용자 질문: {prompt}\")\n",
    "    # Step 1: LLM의 '제안' 받기\n",
    "    response = model.generate_content(prompt)\n",
    "    function_call = response.candidates[0].content.parts[0].function_call\n",
    "    print(f\"🧠 LLM의 제안: {function_call.name}({dict(function_call.args)})\")\n",
    "\n",
    "    # Step 2: 제안된 함수 '실행'\n",
    "    available_functions = {\n",
    "        \"get_return_bigger\": get_return_bigger,\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"get_stock_price\": get_stock_price,\n",
    "    }\n",
    "    if function_call.name in available_functions:\n",
    "        function_to_call = available_functions[function_call.name]\n",
    "        api_response = function_to_call(**function_call.args)\n",
    "        print(f\"🛠️ 함수 실행 결과: {api_response}\")\n",
    "\n",
    "        # Step 3: 실행 결과를 포함하여 최종 답변 요청\n",
    "        conversation_history = [\n",
    "            {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "            response.candidates[0].content,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"parts\": [{\"function_response\": {\"name\": function_call.name, \"response\": {\"content\": api_response}}}],\n",
    "            },\n",
    "        ]\n",
    "        response_final = model.generate_content(conversation_history)\n",
    "        print(f\"💬 최종 답변: {response_final.text}\")\n",
    "        return response_final.text\n",
    "    else:\n",
    "        return \"오류: 모델이 제안한 함수를 찾을 수 없습니다.\"\n",
    "\n",
    "\n",
    "# Agent 실행\n",
    "agent_executor(\"1.1111과 1.9 중에 더 큰 수 뭐야?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAvGWoVRir44"
   },
   "source": [
    "# Section 2. 병렬 Tool Calling (Parallel Tool Calling)\n",
    "실제 사용자는 여러 개의 의도를 하나의 질문에 담아 요청하는 경우가 많습니다. 이때 LLM이 각 의도를 파악하여, 필요한 여러 개의 함수 호출을 단 한 번의 요청으로 동시에 제안하는 기능이 바로 **병렬 Tool Calling**입니다. 이를 통해 불필요한 API 호출 횟수를 줄여 비용과 응답 시간을 최적화할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i1EFI9zajKH0"
   },
   "source": [
    "### 2.1. 병렬 실행을 위한 Agent Executor 개선\n",
    "Section 1.3에서 만든 `agent_executor`를 개선하여, 모델이 여러 개의 함수 호출을 제안하더라도 모두 처리할 수 있는 `parallel_agent_executor`를 구현합니다. 핵심은 `response.candidates[0].content.parts`가 리스트 형태이므로, 이를 순회하며 모든 함수 호출을 실행하고 그 결과를 수집하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hNrfCtlXirBU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 사용자 질문: 1.2와 1.3과 1.111 를 큰 순서대로 알려줘\n",
      "🧠 LLM의 제안 (3개): \n",
      "  - get_return_bigger({'valueB': 1.3, 'valueA': 1.2})\n",
      "  - get_return_bigger({'valueB': 1.111, 'valueA': 1.3})\n",
      "  - get_return_bigger({'valueB': 1.111, 'valueA': 1.2})\n",
      "❌ 오류: 'get_return_bigger' 함수를 찾을 수 없습니다.\n",
      "❌ 오류: 'get_return_bigger' 함수를 찾을 수 없습니다.\n",
      "❌ 오류: 'get_return_bigger' 함수를 찾을 수 없습니다.\n"
     ]
    },
    {
     "ename": "InvalidArgument",
     "evalue": "400 Please use a valid role: user, model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response_final\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# 병렬 Agent 실행\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m \u001b[43mparallel_agent_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1.2와 1.3과 1.111 를 큰 순서대로 알려줘\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 38\u001b[0m, in \u001b[0;36mparallel_agent_executor\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Step 3: 실행 결과들을 모두 포함하여 최종 답변 요청\u001b[39;00m\n\u001b[1;32m     27\u001b[0m conversation_history \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     28\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt}]},\n\u001b[1;32m     29\u001b[0m     response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     }\n\u001b[1;32m     37\u001b[0m ]\n\u001b[0;32m---> 38\u001b[0m response_final \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m💬 최종 답변: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_final\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_final\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:294\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    291\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    293\u001b[0m )\n\u001b[0;32m--> 294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:156\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m     next_sleep \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(next_sleep)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_base.py:214\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    209\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    210\u001b[0m         error_list,\n\u001b[1;32m    211\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    212\u001b[0m         original_timeout,\n\u001b[1;32m    213\u001b[0m     )\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/retry/retry_unary.py:147\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    149\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[1;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mInvalidArgument\u001b[0m: 400 Please use a valid role: user, model."
     ]
    }
   ],
   "source": [
    "def parallel_agent_executor(prompt: str):\n",
    "    print(f\"🚀 사용자 질문: {prompt}\")\n",
    "    # Step 1: LLM의 '제안' 받기\n",
    "    response = model.generate_content(prompt)\n",
    "    function_calls = response.candidates[0].content.parts\n",
    "    print(f\"🧠 LLM의 제안 ({len(function_calls)}개): \")\n",
    "    for fc in function_calls:\n",
    "        print(f\"  - {fc.function_call.name}({dict(fc.function_call.args)})\")\n",
    "\n",
    "    # Step 2: 제안된 모든 함수 '실행'\n",
    "    available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"get_stock_price\": get_stock_price,\n",
    "    }\n",
    "    api_responses = []\n",
    "    for function_call in function_calls:\n",
    "        function_name = function_call.function_call.name\n",
    "        if function_name in available_functions:\n",
    "            function_to_call = available_functions[function_name]\n",
    "            api_response = function_to_call(**function_call.function_call.args)\n",
    "            api_responses.append(api_response)\n",
    "            print(f\"🛠️ '{function_name}' 실행 완료: {api_response}\")\n",
    "        else:\n",
    "            print(f\"❌ 오류: '{function_name}' 함수를 찾을 수 없습니다.\")\n",
    "\n",
    "    # Step 3: 실행 결과들을 모두 포함하여 최종 답변 요청\n",
    "    conversation_history = [\n",
    "        {\"role\": \"user\", \"parts\": [{\"text\": prompt}]},\n",
    "        response.candidates[0].content,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"parts\": [\n",
    "                {\"function_response\": {\"name\": fc.function_call.name, \"response\": {\"content\": resp}}}\n",
    "                for fc, resp in zip(function_calls, api_responses)\n",
    "            ],\n",
    "        },\n",
    "    ]\n",
    "    response_final = model.generate_content(conversation_history)\n",
    "    print(f\"\\n💬 최종 답변: {response_final.text}\")\n",
    "    return response_final.text\n",
    "\n",
    "\n",
    "# 병렬 Agent 실행\n",
    "parallel_agent_executor(\"1.2와 1.3과 1.111 를 큰 순서대로 알려줘\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "256NzVG061sQ"
   },
   "source": [
    "# Section 3. Structured Output: LLM 답변을 원하는 데이터 구조로 통제하기\n",
    "Tool Calling이 LLM의 '행동'을 제어하는 기술이라면, **Structured Output**은 LLM의 '응답' 자체를 우리가 원하는 데이터 구조로 통제하는 강력한 기술입니다. 비정형 텍스트에서 정형 데이터를 추출하여 후속 자동화 작업에 활용하는 실무 시나리오에서 매우 중요합니다.\n",
    "\n",
    "이번 실습에서는 6일차 최종 프로젝트와의 연계성을 고려하여, **arXiv의 논문 초록(비정형 텍스트)에서 논문 제목, 저자, 요약문 등 핵심 메타데이터(정형 데이터)를 정확하게 추출**하는 작업을 수행해 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcMH9TmF63Qh"
   },
   "source": [
    "### 3.1. 데이터 구조를 표현할 Pydantic 모델 정의\n",
    "LLM을 통해 비정형 텍스트에서 추출하고 싶은 정보의 구조를 Pydantic 모델(클래스)로 먼저 정의합니다. 이는 LLM에게 우리가 원하는 결과물의 '청사진'을 제공하는 것과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yczK94dC64pL"
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class ArxivPaperInfo(BaseModel):\n",
    "    \"\"\"arXiv 논문 초록에서 추출한 메타데이터를 담기 위한 데이터 구조입니다.\"\"\"\n",
    "\n",
    "    title: str = Field(..., description=\"논문의 전체 제목\")\n",
    "    authors: List[str] = Field(..., description=\"논문의 저자 목록\")\n",
    "    summary: str = Field(..., description=\"논문의 핵심 내용을 요약한 초록\")\n",
    "    primary_category: str = Field(..., description=\"논문의 주된 연구 분야 카테고리 (예: cs.CL, cs.AI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HerX7aEl7HqY"
   },
   "source": [
    "### 3.2. Instructor 클라이언트 설정 및 정보 추출\n",
    "`instructor` 라이브러리는 기존 Gemini 클라이언트를 '패치(patch)'하여 `response_model`이라는 강력한 기능을 추가합니다. 이 파라미터에 우리가 방금 정의한 `ArxivPaperInfo` 클래스를 전달하면, LLM은 자신의 출력을 해당 Pydantic 모델의 JSON 스키마에 맞추어 생성하도록 강제됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLNr1fAe7IrI"
   },
   "outputs": [],
   "source": [
    "import instructor\n",
    "import arxiv\n",
    "\n",
    "# Instructor를 사용하여 Gemini 클라이언트를 확장합니다.\n",
    "# mode=instructor.Mode.GEMINI_JSON을 명시하여 JSON 출력 모드를 활성화합니다.\n",
    "client = instructor.from_provider(\n",
    "    \"google/gemini-2.5-pro\",\n",
    "    mode=instructor.Mode.GEMINI_JSON,\n",
    ")\n",
    "\n",
    "# 예시로 사용할 최신 AI 논문(Llama 3)의 초록을 arxiv API를 통해 가져옵니다.\n",
    "paper = next(arxiv.Client().results(arxiv.Search(query=\"Llama 3\")))\n",
    "paper_abstract = paper.summary.replace(\"\\n\", \" \")\n",
    "\n",
    "print(\"--- 원본 논문 초록 (비정형 텍스트) ---\")\n",
    "print(paper_abstract)\n",
    "\n",
    "# response_model에 ArxivPaperInfo를 지정하여, 출력을 해당 객체로 강제합니다.\n",
    "paper_info_object = client.messages.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"다음 논문 초록 텍스트에서 핵심 정보를 추출해줘: {paper_abstract}\",\n",
    "        }\n",
    "    ],\n",
    "    response_model=ArxivPaperInfo,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(f\"반환된 객체의 타입: {type(paper_info_object)}\")\n",
    "print(\"--- 추출된 정보 (Pydantic 객체) ---\")\n",
    "print(paper_info_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZkS1c9eC7M3A"
   },
   "source": [
    "### 3.3. 추출된 구조화 데이터의 활용\n",
    "Instructor의 가장 큰 장점은 반환된 결과가 단순 텍스트가 아닌, **타입 검사가 완료된 신뢰할 수 있는 Pydantic 객체**라는 점입니다. 이를 통해 우리는 후속 코드에서 `.title`, `.authors` 와 같이 객체 지향적인 방식으로 안전하고 편리하게 데이터를 다룰 수 있습니다.\n",
    "\n",
    "이렇게 추출된 구조화된 데이터는 데이터베이스에 저장하거나, 다른 API의 입력으로 사용하거나, 최종 보고서의 '참고문헌' 섹션을 자동으로 생성하는 등 다양한 자동화 작업에 즉시 활용될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0oQS-Qkj7N4w"
   },
   "outputs": [],
   "source": [
    "# Pydantic 객체의 각 속성에 직접 접근하여 데이터를 활용합니다.\n",
    "print(f\"논문 제목: {paper_info_object.title}\")\n",
    "print(f\"주 저자: {paper_info_object.authors[0]}\")\n",
    "print(f\"카테고리: {paper_info_object.primary_category}\")\n",
    "\n",
    "# 객체를 JSON으로 변환하여 파일로 저장하거나 다른 시스템으로 전송할 수 있습니다.\n",
    "paper_info_json = paper_info_object.model_dump_json(indent=2)\n",
    "print(\"\\nJSON으로 변환된 결과:\")\n",
    "print(paper_info_json)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
